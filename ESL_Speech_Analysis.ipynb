{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b603bf",
   "metadata": {},
   "source": [
    "# ESL Speech Analysis (Remote Kernel)\n",
    "\n",
    "**Assumptions**\n",
    "- Recording happens locally.\n",
    "- Audio is uploaded as .wav (16 kHz preferred) or .m4a (converted to .wav).\n",
    "- Notebook runs on Paperspace (CPU or GPU).\n",
    "- No microphone access.\n",
    "- .m4a conversion requires ffmpeg available in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74048cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53791366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
      "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (3.2.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
      "Collecting replicate\n",
      "  Downloading replicate-1.0.7-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (4.15.0)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.6.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.15.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (1.23.2)\n",
      "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (16.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.31.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.8)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (69.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/lib/python3/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (5.4.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2023.6.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.23.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.0.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Downloading replicate-1.0.7-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: replicate\n",
      "Successfully installed replicate-1.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Cell 0: Environment Setup (run once)\n",
    "# For .m4a support, pydub needs ffmpeg available in the runtime.\n",
    "!pip install faster-whisper language-tool-python pydub openai replicate -U typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302bb8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.6.1 requires typer<0.10.0,>=0.3.0, but you have typer 0.21.1 which is incompatible.\n",
      "torchvision 0.16.1+cu121 requires torch==2.1.1, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c780eae2a0645949c4f72e60dcd5877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 67 files:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF cache ready at: /notebooks/.hf_cache\n"
     ]
    }
   ],
   "source": [
    "# Cell 0b: Diarization Setup (run once)\n",
    "# Installs pyannote and pins NumPy to avoid ABI issues with pyarrow/pandas.\n",
    "# After running this cell, restart the kernel, then run it again.\n",
    "!pip install -q \"numpy<2\" \"pandas<2.2\" \"pyarrow<16\" pyannote.audio huggingface_hub omegaconf\n",
    "\n",
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Set shared cache dirs to speed up subsequent runs\n",
    "CACHE_DIR = os.path.join(os.getcwd(), \".hf_cache\")\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.environ[\"HF_HOME\"] = CACHE_DIR\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = CACHE_DIR\n",
    "os.environ[\"TORCH_HOME\"] = CACHE_DIR\n",
    "\n",
    "# Pre-download diarization model snapshot to cache (warm cache)\n",
    "snapshot_download(\n",
    "    repo_id=\"pyannote/speaker-diarization\",\n",
    "    cache_dir=CACHE_DIR,\n",
    "    token=os.environ.get(\"HF_TOKEN\"),\n",
    "    local_files_only=False,\n",
    ")\n",
    "print(f\"HF cache ready at: {CACHE_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "903eb591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN set for this session.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# DO NOT DELETE!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "print(\"HF_TOKEN set for this session.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e92c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37dde8af96c4d839da13b8454586688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.wav,.m4a', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# FileUpload widget (in-memory)\n",
    "upload = widgets.FileUpload(accept=\".wav,.m4a\", multiple=False)\n",
    "display(upload)\n",
    "\n",
    "# Global variable to hold the audio content\n",
    "AUDIO_BYTES = None\n",
    "AUDIO_FILENAME = None\n",
    "\n",
    "\n",
    "def _iter_uploaded_files(value):\n",
    "    # ipywidgets can return dict-like (v7) or tuple/list (v8)\n",
    "    if hasattr(value, \"items\"):\n",
    "        for name, file_info in value.items():\n",
    "            yield name, file_info\n",
    "    elif isinstance(value, (list, tuple)):\n",
    "        for file_info in value:\n",
    "            name = file_info.get(\"name\") if isinstance(file_info, dict) else None\n",
    "            yield name, file_info\n",
    "\n",
    "\n",
    "def store_audio(change):\n",
    "    global AUDIO_BYTES, AUDIO_FILENAME\n",
    "    if not upload.value:\n",
    "        return\n",
    "    for name, file_info in _iter_uploaded_files(upload.value):\n",
    "        if isinstance(file_info, dict):\n",
    "            AUDIO_BYTES = file_info.get(\"content\")\n",
    "            AUDIO_FILENAME = name or file_info.get(\"name\")\n",
    "            if AUDIO_BYTES and AUDIO_FILENAME:\n",
    "                print(\n",
    "                    f\"Audio file '{AUDIO_FILENAME}' is now ready in memory for other cells.\"\n",
    "                )\n",
    "\n",
    "\n",
    "# Automatically trigger when a file is uploaded\n",
    "upload.observe(store_audio, names=\"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48f97ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file loaded from upload: audio/20260121 181409.wav\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load most recent audio file from ./audio (.wav or .m4a)\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AUDIO_DIR = \"audio\"\n",
    "SUPPORTED_EXTS = {\".wav\", \".m4a\"}\n",
    "\n",
    "# Prefer in-memory upload if present\n",
    "if \"AUDIO_BYTES\" in globals() and AUDIO_BYTES and AUDIO_FILENAME:\n",
    "    ext = os.path.splitext(AUDIO_FILENAME)[1].lower()\n",
    "    if ext not in SUPPORTED_EXTS:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.join(\n",
    "            AUDIO_DIR, os.path.splitext(AUDIO_FILENAME)[0] + \".wav\"\n",
    "        )\n",
    "        audio = AudioSegment.from_file(io.BytesIO(AUDIO_BYTES), format=\"m4a\")\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    else:\n",
    "        AUDIO_PATH = os.path.join(AUDIO_DIR, AUDIO_FILENAME)\n",
    "        with open(AUDIO_PATH, \"wb\") as f:\n",
    "            f.write(AUDIO_BYTES)\n",
    "\n",
    "    print(f\"Audio file loaded from upload: {AUDIO_PATH}\")\n",
    "else:\n",
    "    if not os.path.isdir(AUDIO_DIR):\n",
    "        raise FileNotFoundError(f\"Directory not found: {AUDIO_DIR}\")\n",
    "\n",
    "    candidates = [\n",
    "        os.path.join(AUDIO_DIR, f)\n",
    "        for f in os.listdir(AUDIO_DIR)\n",
    "        if os.path.splitext(f)[1].lower() in SUPPORTED_EXTS\n",
    "        and os.path.isfile(os.path.join(AUDIO_DIR, f))\n",
    "    ]\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"No .wav or .m4a files found in ./audio. Add a file and try again.\"\n",
    "        )\n",
    "\n",
    "    INPUT_PATH = max(candidates, key=os.path.getmtime)\n",
    "\n",
    "    ext = os.path.splitext(INPUT_PATH)[1].lower()\n",
    "\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.splitext(INPUT_PATH)[0] + \".wav\"\n",
    "        audio = AudioSegment.from_file(INPUT_PATH, format=\"m4a\")\n",
    "        # Convert to mono/16k for best Whisper results\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    elif ext == \".wav\":\n",
    "        AUDIO_PATH = INPUT_PATH\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    print(f\"Audio file loaded: {AUDIO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9664cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicate diarization output:\n",
      "{'language': 'en', 'num_speakers': 2, 'segments': [{'avg_logprob': -0.1593031595493185, 'duration': 7.380000000000001, 'end': 10.32, 'speaker': 'SPEAKER_01', 'start': 2.94, 'text': \"We've been talking about an interest that you enjoy and I'd like to discuss with you one or two more general questions related to this.\", 'words': [{'end': 3.24, 'probability': 0.802001953125, 'speaker': 'SPEAKER_01', 'start': 2.94, 'word': \" We've\"}, {'end': 3.34, 'probability': 0.99658203125, 'speaker': 'SPEAKER_01', 'start': 3.24, 'word': ' been'}, {'end': 3.72, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 3.34, 'word': ' talking'}, {'end': 4.14, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 3.72, 'word': ' about'}, {'end': 4.5, 'probability': 0.990234375, 'speaker': 'SPEAKER_01', 'start': 4.14, 'word': ' an'}, {'end': 4.92, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 4.5, 'word': ' interest'}, {'end': 5.6, 'probability': 0.97607421875, 'speaker': 'SPEAKER_01', 'start': 4.92, 'word': ' that'}, {'end': 5.76, 'probability': 0.99951171875, 'speaker': 'SPEAKER_01', 'start': 5.6, 'word': ' you'}, {'end': 6.3, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 5.76, 'word': ' enjoy'}, {'end': 6.68, 'probability': 0.6552734375, 'speaker': 'SPEAKER_01', 'start': 6.3, 'word': ' and'}, {'end': 6.9, 'probability': 0.96337890625, 'speaker': 'SPEAKER_01', 'start': 6.68, 'word': \" I'd\"}, {'end': 7.02, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 6.9, 'word': ' like'}, {'end': 7.16, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 7.02, 'word': ' to'}, {'end': 7.52, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 7.16, 'word': ' discuss'}, {'end': 7.74, 'probability': 0.99072265625, 'speaker': 'SPEAKER_01', 'start': 7.52, 'word': ' with'}, {'end': 7.86, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 7.74, 'word': ' you'}, {'end': 8.04, 'probability': 0.97705078125, 'speaker': 'SPEAKER_01', 'start': 7.86, 'word': ' one'}, {'end': 8.18, 'probability': 0.9921875, 'speaker': 'SPEAKER_01', 'start': 8.04, 'word': ' or'}, {'end': 8.36, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 8.18, 'word': ' two'}, {'end': 8.58, 'probability': 0.97900390625, 'speaker': 'SPEAKER_01', 'start': 8.36, 'word': ' more'}, {'end': 8.86, 'probability': 0.9970703125, 'speaker': 'SPEAKER_01', 'start': 8.58, 'word': ' general'}, {'end': 9.4, 'probability': 0.99267578125, 'speaker': 'SPEAKER_01', 'start': 8.86, 'word': ' questions'}, {'end': 9.8, 'probability': 0.98828125, 'speaker': 'SPEAKER_01', 'start': 9.4, 'word': ' related'}, {'end': 10.02, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 9.8, 'word': ' to'}, {'end': 10.32, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 10.02, 'word': ' this.'}]}, {'avg_logprob': -0.1593031595493185, 'duration': 3.1999999999999993, 'end': 14.1, 'speaker': 'SPEAKER_01', 'start': 10.9, 'text': \"Let's consider first of all the social benefits of hobbies.\", 'words': [{'end': 11.2, 'probability': 0.983154296875, 'speaker': 'SPEAKER_01', 'start': 10.9, 'word': \" Let's\"}, {'end': 11.64, 'probability': 0.9951171875, 'speaker': 'SPEAKER_01', 'start': 11.2, 'word': ' consider'}, {'end': 12, 'probability': 0.55859375, 'speaker': 'SPEAKER_01', 'start': 11.64, 'word': ' first'}, {'end': 12.2, 'probability': 0.994140625, 'speaker': 'SPEAKER_01', 'start': 12, 'word': ' of'}, {'end': 12.32, 'probability': 0.9951171875, 'speaker': 'SPEAKER_01', 'start': 12.2, 'word': ' all'}, {'end': 12.5, 'probability': 0.8818359375, 'speaker': 'SPEAKER_01', 'start': 12.32, 'word': ' the'}, {'end': 12.92, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 12.5, 'word': ' social'}, {'end': 13.4, 'probability': 0.99609375, 'speaker': 'SPEAKER_01', 'start': 12.92, 'word': ' benefits'}, {'end': 13.7, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 13.4, 'word': ' of'}, {'end': 14.1, 'probability': 0.9853515625, 'speaker': 'SPEAKER_01', 'start': 13.7, 'word': ' hobbies.'}]}, {'avg_logprob': -0.1593031595493185, 'duration': 5.359999999999999, 'end': 20.52, 'speaker': 'SPEAKER_01', 'start': 15.16, 'text': \"What are some of the ways that having a hobby is good for a person's social life?\", 'words': [{'end': 15.8, 'probability': 0.97705078125, 'speaker': 'SPEAKER_01', 'start': 15.16, 'word': ' What'}, {'end': 15.9, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 15.8, 'word': ' are'}, {'end': 16.08, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 15.9, 'word': ' some'}, {'end': 16.18, 'probability': 0.994140625, 'speaker': 'SPEAKER_01', 'start': 16.08, 'word': ' of'}, {'end': 16.26, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 16.18, 'word': ' the'}, {'end': 16.6, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 16.26, 'word': ' ways'}, {'end': 17, 'probability': 0.95849609375, 'speaker': 'SPEAKER_01', 'start': 16.6, 'word': ' that'}, {'end': 17.78, 'probability': 0.99365234375, 'speaker': 'SPEAKER_01', 'start': 17, 'word': ' having'}, {'end': 17.92, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 17.78, 'word': ' a'}, {'end': 18.24, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 17.92, 'word': ' hobby'}, {'end': 18.68, 'probability': 0.9970703125, 'speaker': 'SPEAKER_01', 'start': 18.24, 'word': ' is'}, {'end': 18.88, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 18.68, 'word': ' good'}, {'end': 19.1, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 18.88, 'word': ' for'}, {'end': 19.24, 'probability': 0.9892578125, 'speaker': 'SPEAKER_01', 'start': 19.1, 'word': ' a'}, {'end': 19.74, 'probability': 0.979736328125, 'speaker': 'SPEAKER_01', 'start': 19.24, 'word': \" person's\"}, {'end': 20.08, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 19.74, 'word': ' social'}, {'end': 20.52, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 20.08, 'word': ' life?'}]}, {'avg_logprob': -0.1593031595493185, 'duration': 13.66, 'end': 36.72, 'speaker': 'SPEAKER_00', 'start': 23.06, 'text': 'I think sometimes people need some casual social life that if they have a hobby actually they could probably, for example, connect stamp.', 'words': [{'end': 23.38, 'probability': 0.87255859375, 'speaker': 'SPEAKER_00', 'start': 23.06, 'word': ' I'}, {'end': 23.68, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 23.38, 'word': ' think'}, {'end': 25.02, 'probability': 0.96875, 'speaker': 'SPEAKER_00', 'start': 23.68, 'word': ' sometimes'}, {'end': 26.2, 'probability': 0.986328125, 'speaker': 'SPEAKER_00', 'start': 25.02, 'word': ' people'}, {'end': 27.12, 'probability': 0.994140625, 'speaker': 'SPEAKER_00', 'start': 26.2, 'word': ' need'}, {'end': 28.22, 'probability': 0.96875, 'speaker': 'SPEAKER_00', 'start': 27.12, 'word': ' some'}, {'end': 29.48, 'probability': 0.8466796875, 'speaker': 'SPEAKER_00', 'start': 28.22, 'word': ' casual'}, {'end': 29.98, 'probability': 0.98779296875, 'speaker': 'SPEAKER_00', 'start': 29.48, 'word': ' social'}, {'end': 30.26, 'probability': 0.99365234375, 'speaker': 'SPEAKER_00', 'start': 29.98, 'word': ' life'}, {'end': 30.58, 'probability': 0.56396484375, 'speaker': 'SPEAKER_00', 'start': 30.26, 'word': ' that'}, {'end': 31.36, 'probability': 0.8984375, 'speaker': 'SPEAKER_00', 'start': 30.58, 'word': ' if'}, {'end': 31.62, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 31.42, 'word': ' they'}, {'end': 31.86, 'probability': 0.9970703125, 'speaker': 'SPEAKER_00', 'start': 31.62, 'word': ' have'}, {'end': 31.96, 'probability': 0.998046875, 'speaker': 'SPEAKER_00', 'start': 31.86, 'word': ' a'}, {'end': 32.26, 'probability': 0.99462890625, 'speaker': 'SPEAKER_00', 'start': 31.96, 'word': ' hobby'}, {'end': 32.64, 'probability': 0.59765625, 'speaker': 'SPEAKER_00', 'start': 32.26, 'word': ' actually'}, {'end': 32.84, 'probability': 0.7548828125, 'speaker': 'SPEAKER_00', 'start': 32.64, 'word': ' they'}, {'end': 33.08, 'probability': 0.978515625, 'speaker': 'SPEAKER_00', 'start': 32.84, 'word': ' could'}, {'end': 33.86, 'probability': 0.80810546875, 'speaker': 'SPEAKER_00', 'start': 33.08, 'word': ' probably,'}, {'end': 35.24, 'probability': 0.96484375, 'speaker': 'SPEAKER_00', 'start': 34.06, 'word': ' for'}, {'end': 35.62, 'probability': 0.9970703125, 'speaker': 'SPEAKER_00', 'start': 35.24, 'word': ' example,'}, {'end': 36.24, 'probability': 0.95361328125, 'speaker': 'SPEAKER_00', 'start': 35.86, 'word': ' connect'}, {'end': 36.72, 'probability': 0.56396484375, 'speaker': 'SPEAKER_00', 'start': 36.24, 'word': ' stamp.'}]}, {'avg_logprob': -0.16875000397364298, 'duration': 8.979999999999997, 'end': 45.9, 'speaker': 'SPEAKER_00', 'start': 36.92, 'text': 'They could use this to make new friends and could share the feeling with them and help them to make new friends.', 'words': [{'end': 37.4, 'probability': 0.9951171875, 'speaker': 'SPEAKER_00', 'start': 36.92, 'word': ' They'}, {'end': 37.58, 'probability': 0.99365234375, 'speaker': 'SPEAKER_00', 'start': 37.4, 'word': ' could'}, {'end': 37.84, 'probability': 0.99169921875, 'speaker': 'SPEAKER_00', 'start': 37.58, 'word': ' use'}, {'end': 38.02, 'probability': 0.5244140625, 'speaker': 'SPEAKER_00', 'start': 37.84, 'word': ' this'}, {'end': 38.32, 'probability': 0.9970703125, 'speaker': 'SPEAKER_00', 'start': 38.02, 'word': ' to'}, {'end': 38.62, 'probability': 0.998046875, 'speaker': 'SPEAKER_00', 'start': 38.32, 'word': ' make'}, {'end': 39.06, 'probability': 0.9970703125, 'speaker': 'SPEAKER_00', 'start': 38.62, 'word': ' new'}, {'end': 39.52, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 39.06, 'word': ' friends'}, {'end': 40.66, 'probability': 0.8173828125, 'speaker': 'SPEAKER_00', 'start': 39.52, 'word': ' and'}, {'end': 41.1, 'probability': 0.935546875, 'speaker': 'SPEAKER_00', 'start': 40.66, 'word': ' could'}, {'end': 42.48, 'probability': 0.98193359375, 'speaker': 'SPEAKER_00', 'start': 41.1, 'word': ' share'}, {'end': 43.06, 'probability': 0.82568359375, 'speaker': 'SPEAKER_00', 'start': 42.48, 'word': ' the'}, {'end': 43.52, 'probability': 0.94970703125, 'speaker': 'SPEAKER_00', 'start': 43.06, 'word': ' feeling'}, {'end': 43.76, 'probability': 0.98388671875, 'speaker': 'SPEAKER_00', 'start': 43.52, 'word': ' with'}, {'end': 43.96, 'probability': 0.99658203125, 'speaker': 'SPEAKER_00', 'start': 43.76, 'word': ' them'}, {'end': 44.32, 'probability': 0.9716796875, 'speaker': 'SPEAKER_00', 'start': 43.96, 'word': ' and'}, {'end': 44.62, 'probability': 0.990234375, 'speaker': 'SPEAKER_00', 'start': 44.32, 'word': ' help'}, {'end': 44.84, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 44.62, 'word': ' them'}, {'end': 45.06, 'probability': 0.98828125, 'speaker': 'SPEAKER_00', 'start': 44.84, 'word': ' to'}, {'end': 45.3, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 45.06, 'word': ' make'}, {'end': 45.48, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 45.3, 'word': ' new'}, {'end': 45.9, 'probability': 0.99951171875, 'speaker': 'SPEAKER_00', 'start': 45.48, 'word': ' friends.'}]}, {'avg_logprob': -0.16875000397364298, 'duration': 5.619999999999997, 'end': 52.76, 'speaker': 'SPEAKER_00', 'start': 47.14, 'text': 'I think probably in this way it could increase his social life.', 'words': [{'end': 47.44, 'probability': 0.271240234375, 'speaker': 'SPEAKER_00', 'start': 47.14, 'word': ' I'}, {'end': 47.66, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 47.44, 'word': ' think'}, {'end': 48.58, 'probability': 0.5263671875, 'speaker': 'SPEAKER_00', 'start': 47.66, 'word': ' probably'}, {'end': 48.76, 'probability': 0.86328125, 'speaker': 'SPEAKER_00', 'start': 48.58, 'word': ' in'}, {'end': 48.88, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 48.76, 'word': ' this'}, {'end': 49.12, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 48.88, 'word': ' way'}, {'end': 49.42, 'probability': 0.70068359375, 'speaker': 'SPEAKER_00', 'start': 49.12, 'word': ' it'}, {'end': 49.7, 'probability': 0.9892578125, 'speaker': 'SPEAKER_00', 'start': 49.42, 'word': ' could'}, {'end': 50.64, 'probability': 0.9892578125, 'speaker': 'SPEAKER_00', 'start': 49.7, 'word': ' increase'}, {'end': 52.12, 'probability': 0.98681640625, 'speaker': 'SPEAKER_00', 'start': 50.64, 'word': ' his'}, {'end': 52.48, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 52.12, 'word': ' social'}, {'end': 52.76, 'probability': 0.99755859375, 'speaker': 'SPEAKER_00', 'start': 52.48, 'word': ' life.'}]}, {'avg_logprob': -0.16875000397364298, 'duration': 3, 'end': 55.88, 'speaker': 'SPEAKER_01', 'start': 52.88, 'text': \"Do you think all hobbies are good for a person's social life?\", 'words': [{'end': 53.24, 'probability': 0.8291015625, 'speaker': 'SPEAKER_01', 'start': 52.88, 'word': ' Do'}, {'end': 53.32, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 53.24, 'word': ' you'}, {'end': 53.44, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 53.32, 'word': ' think'}, {'end': 53.6, 'probability': 0.9931640625, 'speaker': 'SPEAKER_01', 'start': 53.44, 'word': ' all'}, {'end': 53.96, 'probability': 0.984375, 'speaker': 'SPEAKER_01', 'start': 53.6, 'word': ' hobbies'}, {'end': 54.28, 'probability': 0.9931640625, 'speaker': 'SPEAKER_01', 'start': 53.96, 'word': ' are'}, {'end': 54.58, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 54.28, 'word': ' good'}, {'end': 54.78, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 54.58, 'word': ' for'}, {'end': 54.92, 'probability': 0.9853515625, 'speaker': 'SPEAKER_01', 'start': 54.78, 'word': ' a'}, {'end': 55.34, 'probability': 0.9765625, 'speaker': 'SPEAKER_01', 'start': 54.92, 'word': \" person's\"}, {'end': 55.64, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 55.34, 'word': ' social'}, {'end': 55.88, 'probability': 0.98193359375, 'speaker': 'SPEAKER_01', 'start': 55.64, 'word': ' life?'}]}, {'avg_logprob': -0.16875000397364298, 'duration': 0.8200000000000003, 'end': 57.51, 'speaker': 'SPEAKER_00', 'start': 56.69, 'text': 'Not really.', 'words': [{'end': 57.27, 'probability': 0.96142578125, 'speaker': 'SPEAKER_00', 'start': 56.69, 'word': ' Not'}, {'end': 57.51, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 57.27, 'word': ' really.'}]}, {'avg_logprob': -0.16875000397364298, 'duration': 3.0799999999999983, 'end': 60.71, 'speaker': 'SPEAKER_00', 'start': 57.63, 'text': 'It really depends on what kind of hobbies to have.', 'words': [{'end': 57.71, 'probability': 0.9921875, 'speaker': 'SPEAKER_00', 'start': 57.63, 'word': ' It'}, {'end': 57.95, 'probability': 0.96435546875, 'speaker': 'SPEAKER_00', 'start': 57.71, 'word': ' really'}, {'end': 58.33, 'probability': 0.99755859375, 'speaker': 'SPEAKER_00', 'start': 57.95, 'word': ' depends'}, {'end': 58.65, 'probability': 0.9873046875, 'speaker': 'SPEAKER_00', 'start': 58.33, 'word': ' on'}, {'end': 59.13, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 58.65, 'word': ' what'}, {'end': 59.43, 'probability': 0.98046875, 'speaker': 'SPEAKER_00', 'start': 59.13, 'word': ' kind'}, {'end': 59.65, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 59.43, 'word': ' of'}, {'end': 60.05, 'probability': 0.92236328125, 'speaker': 'SPEAKER_00', 'start': 59.65, 'word': ' hobbies'}, {'end': 60.37, 'probability': 0.6015625, 'speaker': 'SPEAKER_00', 'start': 60.05, 'word': ' to'}, {'end': 60.71, 'probability': 0.98681640625, 'speaker': 'SPEAKER_00', 'start': 60.37, 'word': ' have.'}]}, {'avg_logprob': -0.19200721860696107, 'duration': 5.440000000000005, 'end': 66.15, 'speaker': 'SPEAKER_00', 'start': 60.71, 'text': 'For example, some people would like to connect a sports car.', 'words': [{'end': 61.25, 'probability': 0.4326171875, 'speaker': 'SPEAKER_00', 'start': 60.71, 'word': ' For'}, {'end': 61.65, 'probability': 0.99560546875, 'speaker': 'SPEAKER_00', 'start': 61.25, 'word': ' example,'}, {'end': 62.07, 'probability': 0.9853515625, 'speaker': 'SPEAKER_00', 'start': 61.93, 'word': ' some'}, {'end': 62.47, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 62.07, 'word': ' people'}, {'end': 63.75, 'probability': 0.9873046875, 'speaker': 'SPEAKER_00', 'start': 62.47, 'word': ' would'}, {'end': 63.97, 'probability': 0.99755859375, 'speaker': 'SPEAKER_00', 'start': 63.75, 'word': ' like'}, {'end': 64.13, 'probability': 0.998046875, 'speaker': 'SPEAKER_00', 'start': 63.97, 'word': ' to'}, {'end': 64.61, 'probability': 0.9521484375, 'speaker': 'SPEAKER_00', 'start': 64.13, 'word': ' connect'}, {'end': 65.59, 'probability': 0.265380859375, 'speaker': 'SPEAKER_00', 'start': 64.61, 'word': ' a'}, {'end': 65.83, 'probability': 0.94091796875, 'speaker': 'SPEAKER_00', 'start': 65.59, 'word': ' sports'}, {'end': 66.15, 'probability': 0.99169921875, 'speaker': 'SPEAKER_00', 'start': 65.83, 'word': ' car.'}]}, {'avg_logprob': -0.19200721860696107, 'duration': 11.079999999999998, 'end': 77.63, 'speaker': 'SPEAKER_00', 'start': 66.55, 'text': \"Actually everyone could do it because as we know it's very expensive and you shouldn't be too addicted to your hobbies.\", 'words': [{'end': 66.91, 'probability': 0.931640625, 'speaker': 'SPEAKER_00', 'start': 66.55, 'word': ' Actually'}, {'end': 68.43, 'probability': 0.1322021484375, 'speaker': 'SPEAKER_00', 'start': 66.91, 'word': ' everyone'}, {'end': 68.77, 'probability': 0.92333984375, 'speaker': 'SPEAKER_00', 'start': 68.43, 'word': ' could'}, {'end': 68.95, 'probability': 0.9931640625, 'speaker': 'SPEAKER_00', 'start': 68.77, 'word': ' do'}, {'end': 69.11, 'probability': 0.96240234375, 'speaker': 'SPEAKER_00', 'start': 68.95, 'word': ' it'}, {'end': 69.47, 'probability': 0.81005859375, 'speaker': 'SPEAKER_00', 'start': 69.11, 'word': ' because'}, {'end': 69.99, 'probability': 0.6171875, 'speaker': 'SPEAKER_00', 'start': 69.47, 'word': ' as'}, {'end': 70.15, 'probability': 0.9912109375, 'speaker': 'SPEAKER_00', 'start': 69.99, 'word': ' we'}, {'end': 70.35, 'probability': 0.99755859375, 'speaker': 'SPEAKER_00', 'start': 70.15, 'word': ' know'}, {'end': 70.77, 'probability': 0.835693359375, 'speaker': 'SPEAKER_00', 'start': 70.35, 'word': \" it's\"}, {'end': 70.95, 'probability': 0.9775390625, 'speaker': 'SPEAKER_00', 'start': 70.77, 'word': ' very'}, {'end': 71.45, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 70.95, 'word': ' expensive'}, {'end': 72.27, 'probability': 0.6826171875, 'speaker': 'SPEAKER_00', 'start': 71.45, 'word': ' and'}, {'end': 74.37, 'probability': 0.97802734375, 'speaker': 'SPEAKER_00', 'start': 72.27, 'word': ' you'}, {'end': 74.93, 'probability': 0.995849609375, 'speaker': 'SPEAKER_00', 'start': 74.37, 'word': \" shouldn't\"}, {'end': 75.33, 'probability': 0.70458984375, 'speaker': 'SPEAKER_00', 'start': 74.93, 'word': ' be'}, {'end': 75.69, 'probability': 0.96337890625, 'speaker': 'SPEAKER_00', 'start': 75.33, 'word': ' too'}, {'end': 76.09, 'probability': 0.986328125, 'speaker': 'SPEAKER_00', 'start': 75.69, 'word': ' addicted'}, {'end': 76.39, 'probability': 0.99462890625, 'speaker': 'SPEAKER_00', 'start': 76.09, 'word': ' to'}, {'end': 77.19, 'probability': 0.947265625, 'speaker': 'SPEAKER_00', 'start': 76.39, 'word': ' your'}, {'end': 77.63, 'probability': 0.958984375, 'speaker': 'SPEAKER_00', 'start': 77.19, 'word': ' hobbies.'}]}, {'avg_logprob': -0.19200721860696107, 'duration': 8.450000000000003, 'end': 86.94, 'speaker': 'SPEAKER_01', 'start': 78.49, 'text': 'So if a person is addicted to their hobbies, if they spend too much time on their hobby, does that have negative effects for a person?', 'words': [{'end': 78.83, 'probability': 0.88427734375, 'speaker': 'SPEAKER_01', 'start': 78.49, 'word': ' So'}, {'end': 79.01, 'probability': 0.95068359375, 'speaker': 'SPEAKER_01', 'start': 78.83, 'word': ' if'}, {'end': 79.11, 'probability': 0.9794921875, 'speaker': 'SPEAKER_01', 'start': 79.01, 'word': ' a'}, {'end': 79.45, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 79.11, 'word': ' person'}, {'end': 79.71, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 79.45, 'word': ' is'}, {'end': 80.07, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 79.71, 'word': ' addicted'}, {'end': 80.35, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 80.07, 'word': ' to'}, {'end': 80.53, 'probability': 0.94287109375, 'speaker': 'SPEAKER_01', 'start': 80.35, 'word': ' their'}, {'end': 80.87, 'probability': 0.96484375, 'speaker': 'SPEAKER_01', 'start': 80.53, 'word': ' hobbies,'}, {'end': 81.53, 'probability': 0.97998046875, 'speaker': 'SPEAKER_01', 'start': 81.11, 'word': ' if'}, {'end': 81.63, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 81.53, 'word': ' they'}, {'end': 81.95, 'probability': 0.9912109375, 'speaker': 'SPEAKER_01', 'start': 81.63, 'word': ' spend'}, {'end': 82.71, 'probability': 0.99267578125, 'speaker': 'SPEAKER_01', 'start': 81.95, 'word': ' too'}, {'end': 82.91, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 82.71, 'word': ' much'}, {'end': 83.21, 'probability': 0.99658203125, 'speaker': 'SPEAKER_01', 'start': 82.91, 'word': ' time'}, {'end': 83.47, 'probability': 0.99560546875, 'speaker': 'SPEAKER_01', 'start': 83.21, 'word': ' on'}, {'end': 83.79, 'probability': 0.966796875, 'speaker': 'SPEAKER_01', 'start': 83.47, 'word': ' their'}, {'end': 84.11, 'probability': 0.962890625, 'speaker': 'SPEAKER_01', 'start': 83.79, 'word': ' hobby,'}, {'end': 84.91, 'probability': 0.99365234375, 'speaker': 'SPEAKER_00', 'start': 84.31, 'word': ' does'}, {'end': 85.3, 'probability': 0.95654296875, 'speaker': 'SPEAKER_01', 'start': 85.16, 'word': ' that'}, {'end': 85.46, 'probability': 0.99658203125, 'speaker': 'SPEAKER_01', 'start': 85.3, 'word': ' have'}, {'end': 85.8, 'probability': 0.9267578125, 'speaker': 'SPEAKER_01', 'start': 85.46, 'word': ' negative'}, {'end': 86.24, 'probability': 0.9794921875, 'speaker': 'SPEAKER_01', 'start': 85.8, 'word': ' effects'}, {'end': 86.52, 'probability': 0.98779296875, 'speaker': 'SPEAKER_01', 'start': 86.24, 'word': ' for'}, {'end': 86.64, 'probability': 0.98779296875, 'speaker': 'SPEAKER_01', 'start': 86.52, 'word': ' a'}, {'end': 86.94, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 86.64, 'word': ' person?'}]}, {'avg_logprob': -0.3195312455296516, 'duration': 0.7999999999999972, 'end': 87.74, 'speaker': 'SPEAKER_00', 'start': 86.94, 'text': 'Yeah.', 'words': [{'end': 87.74, 'probability': 0.323974609375, 'speaker': 'SPEAKER_00', 'start': 86.94, 'word': ' Yeah.'}]}, {'avg_logprob': -0.3195312455296516, 'duration': 10.920000000000002, 'end': 99.2, 'speaker': 'SPEAKER_00', 'start': 88.28, 'text': 'As the example I gave before, if he really addicted to a sports car, actually I think he need to,', 'words': [{'end': 88.42, 'probability': 0.90673828125, 'speaker': 'SPEAKER_00', 'start': 88.28, 'word': ' As'}, {'end': 88.52, 'probability': 0.6484375, 'speaker': 'SPEAKER_00', 'start': 88.42, 'word': ' the'}, {'end': 88.9, 'probability': 0.9951171875, 'speaker': 'SPEAKER_00', 'start': 88.52, 'word': ' example'}, {'end': 89.16, 'probability': 0.97998046875, 'speaker': 'SPEAKER_00', 'start': 88.9, 'word': ' I'}, {'end': 89.38, 'probability': 0.87646484375, 'speaker': 'SPEAKER_00', 'start': 89.16, 'word': ' gave'}, {'end': 89.8, 'probability': 0.9833984375, 'speaker': 'SPEAKER_00', 'start': 89.38, 'word': ' before,'}, {'end': 90.98, 'probability': 0.94140625, 'speaker': 'SPEAKER_00', 'start': 90.3, 'word': ' if'}, {'end': 91.5, 'probability': 0.99169921875, 'speaker': 'SPEAKER_00', 'start': 90.98, 'word': ' he'}, {'end': 91.84, 'probability': 0.74072265625, 'speaker': 'SPEAKER_00', 'start': 91.5, 'word': ' really'}, {'end': 93.54, 'probability': 0.397705078125, 'speaker': 'SPEAKER_00', 'start': 91.84, 'word': ' addicted'}, {'end': 93.98, 'probability': 0.95458984375, 'speaker': 'SPEAKER_00', 'start': 93.54, 'word': ' to'}, {'end': 94.12, 'probability': 0.3076171875, 'speaker': 'SPEAKER_00', 'start': 93.98, 'word': ' a'}, {'end': 95.68, 'probability': 0.36474609375, 'speaker': 'SPEAKER_00', 'start': 94.12, 'word': ' sports'}, {'end': 96.2, 'probability': 0.994140625, 'speaker': 'SPEAKER_00', 'start': 95.68, 'word': ' car,'}, {'end': 97.08, 'probability': 0.8330078125, 'speaker': 'SPEAKER_00', 'start': 96.52, 'word': ' actually'}, {'end': 97.32, 'probability': 0.7744140625, 'speaker': 'SPEAKER_00', 'start': 97.08, 'word': ' I'}, {'end': 97.62, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 97.32, 'word': ' think'}, {'end': 98.7, 'probability': 0.92626953125, 'speaker': 'SPEAKER_00', 'start': 97.62, 'word': ' he'}, {'end': 98.88, 'probability': 0.1588134765625, 'speaker': 'SPEAKER_00', 'start': 98.7, 'word': ' need'}, {'end': 99.2, 'probability': 0.9814453125, 'speaker': 'SPEAKER_00', 'start': 98.88, 'word': ' to,'}]}, {'avg_logprob': -0.3195312455296516, 'duration': 3.1200000000000045, 'end': 103.4, 'speaker': 'SPEAKER_00', 'start': 100.28, 'text': 'he probably spend a lot of money into it and time.', 'words': [{'end': 100.64, 'probability': 0.93505859375, 'speaker': 'SPEAKER_00', 'start': 100.28, 'word': ' he'}, {'end': 100.92, 'probability': 0.9306640625, 'speaker': 'SPEAKER_00', 'start': 100.64, 'word': ' probably'}, {'end': 101.32, 'probability': 0.441162109375, 'speaker': 'SPEAKER_00', 'start': 100.92, 'word': ' spend'}, {'end': 101.56, 'probability': 0.99462890625, 'speaker': 'SPEAKER_00', 'start': 101.32, 'word': ' a'}, {'end': 101.68, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 101.56, 'word': ' lot'}, {'end': 101.8, 'probability': 0.98876953125, 'speaker': 'SPEAKER_00', 'start': 101.68, 'word': ' of'}, {'end': 102.14, 'probability': 0.99951171875, 'speaker': 'SPEAKER_00', 'start': 101.8, 'word': ' money'}, {'end': 102.66, 'probability': 0.8046875, 'speaker': 'SPEAKER_00', 'start': 102.14, 'word': ' into'}, {'end': 102.86, 'probability': 0.99365234375, 'speaker': 'SPEAKER_00', 'start': 102.66, 'word': ' it'}, {'end': 103.06, 'probability': 0.845703125, 'speaker': 'SPEAKER_00', 'start': 102.86, 'word': ' and'}, {'end': 103.4, 'probability': 0.9375, 'speaker': 'SPEAKER_00', 'start': 103.06, 'word': ' time.'}]}, {'avg_logprob': -0.3195312455296516, 'duration': 4.640000000000001, 'end': 109.18, 'speaker': 'SPEAKER_00', 'start': 104.54, 'text': 'If that happened, it probably could damage his family as well.', 'words': [{'end': 104.9, 'probability': 0.8193359375, 'speaker': 'SPEAKER_00', 'start': 104.54, 'word': ' If'}, {'end': 105.5, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 104.9, 'word': ' that'}, {'end': 105.94, 'probability': 0.89306640625, 'speaker': 'SPEAKER_00', 'start': 105.5, 'word': ' happened,'}, {'end': 106.5, 'probability': 0.40576171875, 'speaker': 'SPEAKER_00', 'start': 106.36, 'word': ' it'}, {'end': 107, 'probability': 0.77685546875, 'speaker': 'SPEAKER_00', 'start': 106.5, 'word': ' probably'}, {'end': 107.32, 'probability': 0.9833984375, 'speaker': 'SPEAKER_00', 'start': 107, 'word': ' could'}, {'end': 107.68, 'probability': 0.98828125, 'speaker': 'SPEAKER_00', 'start': 107.32, 'word': ' damage'}, {'end': 108.22, 'probability': 0.99755859375, 'speaker': 'SPEAKER_00', 'start': 107.68, 'word': ' his'}, {'end': 108.58, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 108.22, 'word': ' family'}, {'end': 108.92, 'probability': 0.978515625, 'speaker': 'SPEAKER_00', 'start': 108.58, 'word': ' as'}, {'end': 109.18, 'probability': 0.99951171875, 'speaker': 'SPEAKER_00', 'start': 108.92, 'word': ' well.'}]}, {'avg_logprob': -0.1651218220338983, 'duration': 2.3800000000000097, 'end': 112.68, 'speaker': 'SPEAKER_01', 'start': 110.3, 'text': 'Most people have some sort of interest or hobby.', 'words': [{'end': 110.86, 'probability': 0.607421875, 'speaker': 'SPEAKER_01', 'start': 110.3, 'word': ' Most'}, {'end': 111.12, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 110.86, 'word': ' people'}, {'end': 111.34, 'probability': 0.99658203125, 'speaker': 'SPEAKER_01', 'start': 111.12, 'word': ' have'}, {'end': 111.58, 'probability': 0.9931640625, 'speaker': 'SPEAKER_01', 'start': 111.34, 'word': ' some'}, {'end': 111.78, 'probability': 0.97509765625, 'speaker': 'SPEAKER_01', 'start': 111.58, 'word': ' sort'}, {'end': 111.9, 'probability': 0.9990234375, 'speaker': 'SPEAKER_01', 'start': 111.78, 'word': ' of'}, {'end': 112.18, 'probability': 0.96923828125, 'speaker': 'SPEAKER_01', 'start': 111.9, 'word': ' interest'}, {'end': 112.44, 'probability': 0.9775390625, 'speaker': 'SPEAKER_01', 'start': 112.18, 'word': ' or'}, {'end': 112.68, 'probability': 0.98583984375, 'speaker': 'SPEAKER_01', 'start': 112.44, 'word': ' hobby.'}]}, {'avg_logprob': -0.1651218220338983, 'duration': 3.260000000000005, 'end': 116.18, 'speaker': 'SPEAKER_01', 'start': 112.92, 'text': 'Why do they feel the need to have that, do you think?', 'words': [{'end': 113.2, 'probability': 0.99365234375, 'speaker': 'SPEAKER_01', 'start': 112.92, 'word': ' Why'}, {'end': 113.32, 'probability': 0.9931640625, 'speaker': 'SPEAKER_01', 'start': 113.2, 'word': ' do'}, {'end': 113.48, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 113.32, 'word': ' they'}, {'end': 113.88, 'probability': 0.99267578125, 'speaker': 'SPEAKER_01', 'start': 113.48, 'word': ' feel'}, {'end': 114.04, 'probability': 0.986328125, 'speaker': 'SPEAKER_01', 'start': 113.88, 'word': ' the'}, {'end': 114.38, 'probability': 0.99951171875, 'speaker': 'SPEAKER_01', 'start': 114.04, 'word': ' need'}, {'end': 114.94, 'probability': 0.9912109375, 'speaker': 'SPEAKER_01', 'start': 114.38, 'word': ' to'}, {'end': 115.4, 'probability': 0.9765625, 'speaker': 'SPEAKER_01', 'start': 114.96, 'word': ' have'}, {'end': 115.64, 'probability': 0.994140625, 'speaker': 'SPEAKER_01', 'start': 115.4, 'word': ' that,'}, {'end': 115.84, 'probability': 0.99365234375, 'speaker': 'SPEAKER_01', 'start': 115.76, 'word': ' do'}, {'end': 115.94, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 115.84, 'word': ' you'}, {'end': 116.18, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 115.94, 'word': ' think?'}]}, {'avg_logprob': -0.1651218220338983, 'duration': 11.219999999999985, 'end': 128.2, 'speaker': 'SPEAKER_00', 'start': 116.98, 'text': 'I think the most important reason is because in contemporary society we almost feel a lot of pressure either from work or from study.', 'words': [{'end': 117.54, 'probability': 0.93115234375, 'speaker': 'SPEAKER_00', 'start': 116.98, 'word': ' I'}, {'end': 117.72, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 117.54, 'word': ' think'}, {'end': 117.88, 'probability': 0.9921875, 'speaker': 'SPEAKER_00', 'start': 117.72, 'word': ' the'}, {'end': 118.12, 'probability': 0.998046875, 'speaker': 'SPEAKER_00', 'start': 117.88, 'word': ' most'}, {'end': 118.52, 'probability': 0.998046875, 'speaker': 'SPEAKER_00', 'start': 118.12, 'word': ' important'}, {'end': 118.9, 'probability': 0.99609375, 'speaker': 'SPEAKER_00', 'start': 118.52, 'word': ' reason'}, {'end': 119.4, 'probability': 0.9921875, 'speaker': 'SPEAKER_00', 'start': 118.9, 'word': ' is'}, {'end': 119.68, 'probability': 0.9521484375, 'speaker': 'SPEAKER_00', 'start': 119.4, 'word': ' because'}, {'end': 120, 'probability': 0.96923828125, 'speaker': 'SPEAKER_00', 'start': 119.68, 'word': ' in'}, {'end': 121.08, 'probability': 0.96875, 'speaker': 'SPEAKER_00', 'start': 120, 'word': ' contemporary'}, {'end': 121.72, 'probability': 0.98046875, 'speaker': 'SPEAKER_00', 'start': 121.08, 'word': ' society'}, {'end': 123.64, 'probability': 0.6748046875, 'speaker': 'SPEAKER_00', 'start': 121.72, 'word': ' we'}, {'end': 124.02, 'probability': 0.99169921875, 'speaker': 'SPEAKER_00', 'start': 123.64, 'word': ' almost'}, {'end': 124.44, 'probability': 0.99267578125, 'speaker': 'SPEAKER_00', 'start': 124.02, 'word': ' feel'}, {'end': 125, 'probability': 0.9951171875, 'speaker': 'SPEAKER_00', 'start': 124.44, 'word': ' a'}, {'end': 125.18, 'probability': 0.9990234375, 'speaker': 'SPEAKER_00', 'start': 125, 'word': ' lot'}, {'end': 125.44, 'probability': 0.9970703125, 'speaker': 'SPEAKER_00', 'start': 125.18, 'word': ' of'}, {'end': 126, 'probability': 0.9970703125, 'speaker': 'SPEAKER_00', 'start': 125.44, 'word': ' pressure'}, {'end': 126.82, 'probability': 0.6328125, 'speaker': 'SPEAKER_00', 'start': 126, 'word': ' either'}, {'end': 127.1, 'probability': 0.99609375, 'speaker': 'SPEAKER_00', 'start': 126.82, 'word': ' from'}, {'end': 127.4, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 127.1, 'word': ' work'}, {'end': 127.62, 'probability': 0.99365234375, 'speaker': 'SPEAKER_00', 'start': 127.4, 'word': ' or'}, {'end': 127.8, 'probability': 0.99267578125, 'speaker': 'SPEAKER_00', 'start': 127.62, 'word': ' from'}, {'end': 128.2, 'probability': 0.9775390625, 'speaker': 'SPEAKER_00', 'start': 127.8, 'word': ' study.'}]}, {'avg_logprob': -0.25408379327167163, 'duration': 5.960000000000008, 'end': 134.16, 'speaker': 'SPEAKER_00', 'start': 128.2, 'text': 'So we need some casual activity to release our pressure.', 'words': [{'end': 129.3, 'probability': 0.2303466796875, 'speaker': 'SPEAKER_00', 'start': 128.2, 'word': ' So'}, {'end': 129.86, 'probability': 0.7451171875, 'speaker': 'SPEAKER_00', 'start': 129.3, 'word': ' we'}, {'end': 130.06, 'probability': 0.990234375, 'speaker': 'SPEAKER_00', 'start': 129.86, 'word': ' need'}, {'end': 130.46, 'probability': 0.9931640625, 'speaker': 'SPEAKER_00', 'start': 130.06, 'word': ' some'}, {'end': 131.48, 'probability': 0.245361328125, 'speaker': 'SPEAKER_00', 'start': 130.46, 'word': ' casual'}, {'end': 132.02, 'probability': 0.9912109375, 'speaker': 'SPEAKER_00', 'start': 131.48, 'word': ' activity'}, {'end': 132.42, 'probability': 0.99560546875, 'speaker': 'SPEAKER_00', 'start': 132.02, 'word': ' to'}, {'end': 132.88, 'probability': 0.994140625, 'speaker': 'SPEAKER_00', 'start': 132.42, 'word': ' release'}, {'end': 133.32, 'probability': 0.99169921875, 'speaker': 'SPEAKER_00', 'start': 132.88, 'word': ' our'}, {'end': 134.16, 'probability': 0.9873046875, 'speaker': 'SPEAKER_00', 'start': 133.32, 'word': ' pressure.'}]}, {'avg_logprob': -0.25408379327167163, 'duration': 1.839999999999975, 'end': 136.2, 'speaker': 'SPEAKER_01', 'start': 134.36, 'text': 'How does it release the pressure do you think?', 'words': [{'end': 134.52, 'probability': 0.89599609375, 'speaker': 'SPEAKER_01', 'start': 134.36, 'word': ' How'}, {'end': 134.72, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 134.52, 'word': ' does'}, {'end': 134.84, 'probability': 0.98583984375, 'speaker': 'SPEAKER_01', 'start': 134.72, 'word': ' it'}, {'end': 135.14, 'probability': 0.99169921875, 'speaker': 'SPEAKER_01', 'start': 134.84, 'word': ' release'}, {'end': 135.36, 'probability': 0.98291015625, 'speaker': 'SPEAKER_01', 'start': 135.14, 'word': ' the'}, {'end': 135.66, 'probability': 0.998046875, 'speaker': 'SPEAKER_01', 'start': 135.36, 'word': ' pressure'}, {'end': 135.86, 'probability': 0.56689453125, 'speaker': 'SPEAKER_01', 'start': 135.66, 'word': ' do'}, {'end': 135.96, 'probability': 0.99853515625, 'speaker': 'SPEAKER_01', 'start': 135.86, 'word': ' you'}, {'end': 136.2, 'probability': 0.99609375, 'speaker': 'SPEAKER_01', 'start': 135.96, 'word': ' think?'}]}, {'avg_logprob': -0.25408379327167163, 'duration': 6.420000000000016, 'end': 145.4, 'speaker': 'SPEAKER_00', 'start': 138.98, 'text': 'I think people do have hobbies because they enjoy doing this kind of activity.', 'words': [{'end': 139.32, 'probability': 0.908203125, 'speaker': 'SPEAKER_00', 'start': 138.98, 'word': ' I'}, {'end': 139.54, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 139.32, 'word': ' think'}, {'end': 139.88, 'probability': 0.98828125, 'speaker': 'SPEAKER_00', 'start': 139.54, 'word': ' people'}, {'end': 140.08, 'probability': 0.9833984375, 'speaker': 'SPEAKER_00', 'start': 139.88, 'word': ' do'}, {'end': 140.32, 'probability': 0.99267578125, 'speaker': 'SPEAKER_00', 'start': 140.08, 'word': ' have'}, {'end': 140.62, 'probability': 0.16015625, 'speaker': 'SPEAKER_00', 'start': 140.32, 'word': ' hobbies'}, {'end': 141, 'probability': 0.97998046875, 'speaker': 'SPEAKER_00', 'start': 140.62, 'word': ' because'}, {'end': 141.34, 'probability': 0.99853515625, 'speaker': 'SPEAKER_00', 'start': 141, 'word': ' they'}, {'end': 141.9, 'probability': 0.916015625, 'speaker': 'SPEAKER_00', 'start': 141.34, 'word': ' enjoy'}, {'end': 143.6, 'probability': 0.93017578125, 'speaker': 'SPEAKER_00', 'start': 141.9, 'word': ' doing'}, {'end': 144.56, 'probability': 0.97509765625, 'speaker': 'SPEAKER_00', 'start': 143.6, 'word': ' this'}, {'end': 144.78, 'probability': 0.99365234375, 'speaker': 'SPEAKER_00', 'start': 144.56, 'word': ' kind'}, {'end': 144.92, 'probability': 0.99951171875, 'speaker': 'SPEAKER_00', 'start': 144.78, 'word': ' of'}, {'end': 145.4, 'probability': 0.9775390625, 'speaker': 'SPEAKER_00', 'start': 144.92, 'word': ' activity.'}]}, {'avg_logprob': -0.3243371212121212, 'duration': 0.12000000000000455, 'end': 145.52, 'speaker': 'SPEAKER_00', 'start': 145.4, 'text': 'activity.', 'words': [{'end': 145.52, 'probability': 0.0032444000244140625, 'speaker': 'SPEAKER_00', 'start': 145.4, 'word': ' activity.'}]}, {'avg_logprob': -0.3243371212121212, 'duration': 8.900000000000006, 'end': 154.62, 'speaker': 'SPEAKER_00', 'start': 145.72, 'text': 'So it probably could help them to temporarily forget what happened for the day walk.', 'words': [{'end': 146.3, 'probability': 0.7939453125, 'speaker': 'SPEAKER_00', 'start': 145.72, 'word': ' So'}, {'end': 147.44, 'probability': 0.6328125, 'speaker': 'SPEAKER_00', 'start': 146.3, 'word': ' it'}, {'end': 147.76, 'probability': 0.66796875, 'speaker': 'SPEAKER_00', 'start': 147.44, 'word': ' probably'}, {'end': 148.22, 'probability': 0.986328125, 'speaker': 'SPEAKER_00', 'start': 147.76, 'word': ' could'}, {'end': 148.52, 'probability': 0.99462890625, 'speaker': 'SPEAKER_00', 'start': 148.22, 'word': ' help'}, {'end': 148.78, 'probability': 0.99658203125, 'speaker': 'SPEAKER_00', 'start': 148.52, 'word': ' them'}, {'end': 149.06, 'probability': 0.92822265625, 'speaker': 'SPEAKER_00', 'start': 148.78, 'word': ' to'}, {'end': 149.98, 'probability': 0.9873046875, 'speaker': 'SPEAKER_00', 'start': 149.06, 'word': ' temporarily'}, {'end': 150.5, 'probability': 0.99658203125, 'speaker': 'SPEAKER_00', 'start': 149.98, 'word': ' forget'}, {'end': 150.88, 'probability': 0.98876953125, 'speaker': 'SPEAKER_00', 'start': 150.5, 'word': ' what'}, {'end': 151.28, 'probability': 0.974609375, 'speaker': 'SPEAKER_00', 'start': 150.88, 'word': ' happened'}, {'end': 151.58, 'probability': 0.76025390625, 'speaker': 'SPEAKER_00', 'start': 151.28, 'word': ' for'}, {'end': 151.82, 'probability': 0.9716796875, 'speaker': 'SPEAKER_00', 'start': 151.58, 'word': ' the'}, {'end': 152.64, 'probability': 0.81494140625, 'speaker': 'SPEAKER_00', 'start': 151.82, 'word': ' day'}, {'end': 154.62, 'probability': 0.491943359375, 'speaker': 'SPEAKER_00', 'start': 152.64, 'word': ' walk.'}]}, {'avg_logprob': -0.3243371212121212, 'duration': 2.700000000000017, 'end': 158.12, 'speaker': 'SPEAKER_00', 'start': 155.42, 'text': 'Have a moment just for yourself.', 'words': [{'end': 155.76, 'probability': 0.87890625, 'speaker': 'SPEAKER_00', 'start': 155.42, 'word': ' Have'}, {'end': 155.98, 'probability': 0.98974609375, 'speaker': 'SPEAKER_00', 'start': 155.76, 'word': ' a'}, {'end': 157.22, 'probability': 0.99462890625, 'speaker': 'SPEAKER_00', 'start': 155.98, 'word': ' moment'}, {'end': 157.54, 'probability': 0.966796875, 'speaker': 'SPEAKER_00', 'start': 157.22, 'word': ' just'}, {'end': 157.76, 'probability': 0.99755859375, 'speaker': 'SPEAKER_00', 'start': 157.54, 'word': ' for'}, {'end': 158.12, 'probability': 0.9921875, 'speaker': 'SPEAKER_00', 'start': 157.76, 'word': ' yourself.'}]}, {'avg_logprob': -0.9733965482030597, 'duration': 0.7199999999999989, 'end': 158.84, 'speaker': 'SPEAKER_01', 'start': 158.12, 'text': 'Okay.', 'words': [{'end': 158.84, 'probability': 0.5224609375, 'speaker': 'SPEAKER_01', 'start': 158.12, 'word': ' Okay.'}]}, {'avg_logprob': -0.9733965482030597, 'duration': 0.2599999999999909, 'end': 159.78, 'speaker': 'SPEAKER_01', 'start': 159.52, 'text': 'Hello.', 'words': [{'end': 159.78, 'probability': 0.0006489753723144531, 'speaker': 'SPEAKER_01', 'start': 159.52, 'word': ' Hello.'}]}, {'avg_logprob': -0.7000713547070821, 'duration': 0.020000000000010232, 'end': 159.8, 'speaker': 'SPEAKER_01', 'start': 159.78, 'text': 'Thank you.', 'words': [{'end': 159.8, 'probability': 0.11553955078125, 'speaker': 'SPEAKER_01', 'start': 159.78, 'word': ' Thank'}, {'end': 159.8, 'probability': 0.99755859375, 'speaker': 'SPEAKER_01', 'start': 159.8, 'word': ' you.'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# Cell 0c: Replicate diarization (Whisper + diarization as a service)\n",
    "# Put your Replicate API key here (or set in environment before running):\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_UdBzdYuIUsDW5MWGvuvgchX7FrxJvho3Vj88j\"\n",
    "\n",
    "import os\n",
    "import replicate\n",
    "\n",
    "# Ensure audio is prepared (run Cell 1 first to set AUDIO_PATH)\n",
    "if \"AUDIO_PATH\" not in globals():\n",
    "    raise RuntimeError(\"AUDIO_PATH not set. Run the audio load cell first.\")\n",
    "\n",
    "if not os.environ.get(\"REPLICATE_API_TOKEN\"):\n",
    "    raise RuntimeError(\"REPLICATE_API_TOKEN not set. Add it in this cell and re-run.\")\n",
    "\n",
    "# Replicate diarization settings\n",
    "NUM_SPEAKERS = 2  # set to None to autodetect\n",
    "GROUP_SEGMENTS = True  # merge short same-speaker segments\n",
    "\n",
    "# Run diarization on Replicate (pin to a model version)\n",
    "\n",
    "model_id = \"thomasmol/whisper-diarization:1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886\"\n",
    "with open(AUDIO_PATH, \"rb\") as f:\n",
    "    input_payload = {\n",
    "        \"file\": f,\n",
    "        \"output\": \"json\",\n",
    "        \"group_segments\": GROUP_SEGMENTS,\n",
    "    }\n",
    "    if NUM_SPEAKERS:\n",
    "        input_payload[\"num_speakers\"] = NUM_SPEAKERS\n",
    "    replicate_output = replicate.run(\n",
    "        model_id,\n",
    "        input=input_payload,\n",
    "    )\n",
    "\n",
    "# Save results for downstream use\n",
    "REPLICATE_DIARIZATION = replicate_output\n",
    "\n",
    "print(\"Replicate diarization output:\")\n",
    "print(replicate_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa896dc",
   "metadata": {},
   "source": [
    "output = replicate.run(\n",
    "    \"victor-upmeet/whisperx:84d2ad2d6194fe98a17d2b60bef1c7f910c46b2f6fd38996ca457afd9c8abfcb\",\n",
    "    input={\n",
    "        \"debug\": False,\n",
    "        \"vad_onset\": 0.5,\n",
    "        \"audio_file\": \"https://replicate.delivery/pbxt/JrvsggK5WvFQ4Q53h4ugPbXW0LK2BLnMZm2dCPhM8bodUq5w/OSR_uk_000_0050_8k.wav\",\n",
    "        \"batch_size\": 64,\n",
    "        \"vad_offset\": 0.363,\n",
    "        \"diarization\": False,\n",
    "        \"temperature\": 0,\n",
    "        \"align_output\": False,\n",
    "        \"language_detection_min_prob\": 0,\n",
    "        \"language_detection_max_tries\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "print(output)\n",
    "\n",
    "model1:\n",
    "model_id = \"thomasmol/whisper-diarization:1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886\"\n",
    "with open(AUDIO_PATH, \"rb\") as f:\n",
    "    input_payload = {\n",
    "        \"file\": f,\n",
    "        \"output\": \"json\",\n",
    "        \"group_segments\": GROUP_SEGMENTS,\n",
    "    }\n",
    "    if NUM_SPEAKERS:\n",
    "        input_payload[\"num_speakers\"] = NUM_SPEAKERS\n",
    "    replicate_output = replicate.run(\n",
    "        model_id,\n",
    "        input=input_payload,\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cf48b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN-READABLE DIARIZATION:\n",
      "\n",
      "[SPEAKER_01] 00:02.94–00:20.52: We've been talking about an interest that you enjoy and I'd like to discuss with you one or two more general questions related to this. Let's consider first of all the social benefits of hobbies. What are some of the ways that having a hobby is good for a person's social life?\n",
      "[SPEAKER_00] 00:23.06–00:52.76: I think sometimes people need some casual social life that if they have a hobby actually they could probably, for example, connect stamp. They could use this to make new friends and could share the feeling with them and help them to make new friends. I think probably in this way it could increase his social life.\n",
      "[SPEAKER_01] 00:52.88–00:55.88: Do you think all hobbies are good for a person's social life?\n",
      "[SPEAKER_00] 00:56.69–01:17.63: Not really. It really depends on what kind of hobbies to have. For example, some people would like to connect a sports car. Actually everyone could do it because as we know it's very expensive and you shouldn't be too addicted to your hobbies.\n",
      "[SPEAKER_01] 01:18.49–01:26.94: So if a person is addicted to their hobbies, if they spend too much time on their hobby, does that have negative effects for a person?\n",
      "[SPEAKER_00] 01:26.94–01:49.18: Yeah. As the example I gave before, if he really addicted to a sports car, actually I think he need to, he probably spend a lot of money into it and time. If that happened, it probably could damage his family as well.\n",
      "[SPEAKER_01] 01:50.30–01:56.18: Most people have some sort of interest or hobby. Why do they feel the need to have that, do you think?\n",
      "[SPEAKER_00] 01:56.98–02:14.16: I think the most important reason is because in contemporary society we almost feel a lot of pressure either from work or from study. So we need some casual activity to release our pressure.\n",
      "[SPEAKER_01] 02:14.36–02:16.20: How does it release the pressure do you think?\n",
      "[SPEAKER_00] 02:18.98–02:38.12: I think people do have hobbies because they enjoy doing this kind of activity. activity. So it probably could help them to temporarily forget what happened for the day walk. Have a moment just for yourself.\n",
      "[SPEAKER_01] 02:38.12–02:39.80: Okay. Hello. Thank you.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Human-readable diarization output (from Replicate)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def _format_time(sec):\n",
    "    m = int(sec // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{m:02d}:{s:05.2f}\"\n",
    "\n",
    "\n",
    "def _normalize_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = re.sub(r\"[\\W_]+\", \"\", t)\n",
    "    return t\n",
    "\n",
    "\n",
    "def _dedupe_sentences(text):\n",
    "    # Remove consecutive duplicate sentences after splitting on punctuation\n",
    "    parts = re.split(r\"(?<=[.!?])\\s+\", text.strip())\n",
    "    out = []\n",
    "    last_norm = None\n",
    "    for p in parts:\n",
    "        if not p:\n",
    "            continue\n",
    "        norm = _normalize_text(p)\n",
    "        if norm and norm == last_norm:\n",
    "            continue\n",
    "        out.append(p)\n",
    "        last_norm = norm\n",
    "    return \" \".join(out)\n",
    "\n",
    "\n",
    "def _merge_segments(segments):\n",
    "    merged = []\n",
    "    last_text_norm = None\n",
    "    for seg in segments:\n",
    "        speaker = seg.get(\"speaker\") or \"UNKNOWN\"\n",
    "        text = (seg.get(\"text\") or \"\").strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        start = seg.get(\"start\", 0.0)\n",
    "        end = seg.get(\"end\", 0.0)\n",
    "        # If speaker is UNKNOWN, stick with previous speaker when possible\n",
    "        if speaker == \"UNKNOWN\" and merged:\n",
    "            speaker = merged[-1][\"speaker\"]\n",
    "        text = _dedupe_sentences(text)\n",
    "        text_norm = _normalize_text(text)\n",
    "        if text_norm and text_norm == last_text_norm:\n",
    "            # Skip exact repeat chunk\n",
    "            continue\n",
    "        if merged and merged[-1][\"speaker\"] == speaker:\n",
    "            # Merge consecutive same-speaker chunks\n",
    "            merged[-1][\"end\"] = end\n",
    "            merged[-1][\"text\"] += \" \" + text\n",
    "        else:\n",
    "            merged.append(\n",
    "                {\"speaker\": speaker, \"start\": start, \"end\": end, \"text\": text}\n",
    "            )\n",
    "        last_text_norm = text_norm\n",
    "    return merged\n",
    "\n",
    "\n",
    "def _pretty_print_replicate(output):\n",
    "    if not output:\n",
    "        print(\n",
    "            \"No Replicate output available. Run the Replicate diarization cell first.\"\n",
    "        )\n",
    "        return\n",
    "    # Replicate returns a dict with `segments` or a list in some cases\n",
    "    segments = None\n",
    "    if isinstance(output, dict):\n",
    "        segments = output.get(\"segments\")\n",
    "    elif isinstance(output, list):\n",
    "        segments = output\n",
    "    if not segments:\n",
    "        print(\"No segments found in Replicate output.\")\n",
    "        return\n",
    "    merged = _merge_segments(segments)\n",
    "    if not merged:\n",
    "        print(\"No usable segments after merging.\")\n",
    "        return\n",
    "    print(\"HUMAN-READABLE DIARIZATION:\\n\")\n",
    "    last_speaker = None\n",
    "    for seg in merged:\n",
    "        speaker = seg[\"speaker\"]\n",
    "        start = _format_time(seg.get(\"start\", 0.0))\n",
    "        end = _format_time(seg.get(\"end\", 0.0))\n",
    "        text = seg[\"text\"]\n",
    "        if speaker != last_speaker:\n",
    "            print(f\"[{speaker}] {start}–{end}: {text}\")\n",
    "            last_speaker = speaker\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "\n",
    "# Use saved output from the Replicate cell\n",
    "_pretty_print_replicate(globals().get(\"REPLICATE_DIARIZATION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db067a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESL ISSUES:\n",
      "\n",
      "- | Error Type | Student Examples (from transcript only) | Better Versions | Why Target This |\n",
      "|---|---|---|---|\n",
      "| Word Choice / Collocation | “need some casual social life” | “need some casual social interaction” / “need a casual social life” | Big naturalness payoff; quick swaps improve clarity. |\n",
      "|  | “connect stamp” | “collect stamps” | High clarity impact (wrong verb). |\n",
      "|  | “connect a sports car” | “collect sports cars” | High clarity impact; repeats the same verb issue. |\n",
      "|  | “share the feeling with them” | “share their interest with them” / “share that hobby with them” | More accurate meaning; easy real-time fix. |\n",
      "|  | “increase his social life” | “improve their social life” / “expand their social circle” | More natural phrasing + pronoun consistency. |\n",
      "|  | “release our pressure” | “relieve our stress/pressure” | Common collocation; frequent in IELTS-style answers. |\n",
      "|  | “what happened for the day walk” | “what happened during the day” | Major clarity issue; quick correction. |\n",
      "| Prepositions | “depends on what kind of hobbies to have” | “depends on what kind of hobbies you have” | Recurring pattern; improves grammar accuracy fast. |\n",
      "|  | “spend a lot of money into it” | “spend a lot of money on it” | Very common preposition error; easy to correct on the spot. |\n",
      "| Verb Forms / Missing Verbs | “it really depends on what kind of hobbies to have” | “it really depends on what kind of hobbies you have” | Clear, high-frequency grammar point. |\n",
      "|  | “if he really addicted to a sports car” | “if he’s really addicted to sports cars” | Missing ‘be’ reduces accuracy and fluency. |\n",
      "|  | “I think he need to” | “I think he needs to” | Simple 3rd person ‘-s’; quick fix. |\n",
      "|  | “he probably spend a lot of money” | “he probably spends a lot of money” | Same 3rd person ‘-s’; recurring. |\n",
      "| Pronouns / Agreement | “increase his social life” | “improve their social life” / “improve a person’s social life” | Consistency (person → they) improves clarity and formality. |\n",
      "| Sentence Structure / Clarity | “I think sometimes people need some casual social life that if they have a hobby actually they could probably…” | “I think people sometimes need casual social interaction. If they have a hobby, they can…” | Long, tangled sentence reduces clarity; easy to split in live feedback. |\n",
      "|  | “Actually everyone could do it because as we know it's very expensive” | “Actually, not everyone can do it because it’s very expensive.” | Logic/meaning flips; high clarity impact. |\n",
      "| Fillers / Repetition | “actually… probably… actually…” | Reduce to one: “actually” OR none | Quick fluency win; cleaner delivery. |\n",
      "|  | “activity. activity.” | “activity.” | Easy to correct; improves smoothness. |\n",
      "\n",
      "Highest-ROI Targets for Live Feedback\n",
      "1) Word Choice / Collocation\n",
      "2) Verb Forms / Missing Verbs\n",
      "3) Sentence Structure / Clarity\n",
      "  Context: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: ESL Error Detection (OpenAI via HTTP)\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "OPENAI_MODEL = \"gpt-5.2\"\n",
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "def _extract_transcript_from_replicate(output):\n",
    "    if isinstance(output, dict):\n",
    "        if \"text\" in output and isinstance(output[\"text\"], str):\n",
    "            return output[\"text\"].strip()\n",
    "        segments = output.get(\"segments\")\n",
    "        if isinstance(segments, list):\n",
    "            parts = []\n",
    "            for seg in segments:\n",
    "                if isinstance(seg, dict):\n",
    "                    t = (seg.get(\"text\") or \"\").strip()\n",
    "                    if t:\n",
    "                        parts.append(t)\n",
    "            if parts:\n",
    "                return \" \".join(parts)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Use Whisper transcript if available; otherwise fall back to Replicate output\n",
    "if \"transcript\" not in globals() or not transcript:\n",
    "    transcript = _extract_transcript_from_replicate(\n",
    "        globals().get(\"REPLICATE_DIARIZATION\")\n",
    "    )\n",
    "    if not transcript:\n",
    "        raise RuntimeError(\n",
    "            \"Transcript not available. Run the Whisper/WhisperX cell first.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_issue_type(match):\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"type\", \"UNKNOWN\")\n",
    "    if hasattr(match, \"ruleId\"):\n",
    "        return match.ruleId\n",
    "    if hasattr(match, \"rule_id\"):\n",
    "        return match.rule_id\n",
    "    if hasattr(match, \"rule\"):\n",
    "        rule = match.rule\n",
    "        if isinstance(rule, dict) and \"id\" in rule:\n",
    "            return rule[\"id\"]\n",
    "        if hasattr(rule, \"id\"):\n",
    "            return rule.id\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    print(\"OPENAI_API_KEY not set. Set it to enable OpenAI-based ESL checks.\")\n",
    "    matches = []\n",
    "else:\n",
    "    system_msg = (\n",
    "        \"You are an ESL pronunciation and fluency coach.\\n\"\n",
    "        \"I will give you a transcript with multiple speakers.\\n\"\n",
    "        \"Task:\\n\"\n",
    "        \"Analyze ONLY the replies of the second speaker.\\n\"\n",
    "        \"Produce a concise, classroom-ready feedback table that is useful for on-the-fly correction during a live lesson.\\n\"\n",
    "        \"Strict requirements:\\n\"\n",
    "        \"1. Group all errors by error type (for example: Articles, Prepositions, Word Choice, Sentence Structure, Pronouns, Idiomatic Expression, Fillers).\\n\"\n",
    "        \"2. Under each error type, list ALL relevant examples that actually appear in the transcript. Do NOT invent or generalize examples.\\n\"\n",
    "        \"3. For each example, provide a natural corrected version.\\n\"\n",
    "        \"4. Include a brief reason for why this error type is a good feedback target (high frequency, clarity impact, fluency payoff, or teachability).\\n\"\n",
    "        \"5. Prioritize errors that:\\n\"\n",
    "        \"   * are recurring\\n\"\n",
    "        \"   * reduce clarity or naturalness\\n\"\n",
    "        \"   * are easy to correct in real time\\n\"\n",
    "        \"6. Do NOT include errors that are not attested in the transcript.\\n\"\n",
    "        \"7. Do NOT over-explain. Keep it concise and practical for live teaching.\\n\"\n",
    "        \"Output format:\\n\"\n",
    "        \"Title: On-the-Fly Feedback Table (Speaker 2)\\n\"\n",
    "        \"Table columns:\\n\"\n",
    "        \"* Error Type\\n\"\n",
    "        \"* Student Examples (from transcript only)\\n\"\n",
    "        \"* Better Versions\\n\"\n",
    "        \"* Why Target This\\n\"\n",
    "        \"After the table, add a short section:\\n\"\n",
    "        \"Highest-ROI Targets for Live Feedback\\n\"\n",
    "        \"List the top 2 to 3 error types that give the biggest improvement if corrected first.\\n\"\n",
    "        \"Do NOT add teaching tips, drilling activities, or lesson plans.\\n\"\n",
    "        \"Do NOT add examples that are not in the transcript.\"\n",
    "    )\n",
    "    user_msg = f\"Transcript:\\n{transcript}\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"issues\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"type\": {\"type\": \"string\"},\n",
    "                        \"message\": {\"type\": \"string\"},\n",
    "                        \"context\": {\"type\": \"string\"},\n",
    "                        \"suggestion\": {\"type\": \"string\"},\n",
    "                    },\n",
    "                    \"required\": [\"type\", \"message\", \"context\", \"suggestion\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"issues\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": OPENAI_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"name\": \"esl_issues\", \"schema\": schema, \"strict\": True},\n",
    "        },\n",
    "    }\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=payload,\n",
    "        timeout=60,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    resp = r.json()\n",
    "\n",
    "    if \"choices\" in resp and len(resp[\"choices\"]) > 0:\n",
    "        content_str = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        data = json.loads(content_str)\n",
    "        matches = data.get(\"issues\", [])\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unexpected response format from OpenAI: {json.dumps(resp, indent=2)}\"\n",
    "        )\n",
    "\n",
    "print(\"ESL ISSUES:\\n\")\n",
    "for m in matches:\n",
    "    if isinstance(m, dict):\n",
    "        print(f\"- {m.get('message', '')}\")\n",
    "        print(f\"  Context: {m.get('context', '')}\")\n",
    "        if m.get(\"suggestion\"):\n",
    "            print(f\"  Suggestion: {m.get('suggestion')}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"- {m.message}\")\n",
    "        print(f\"  Context: {m.context}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b93aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSCRIPT:\n",
      "We've been talking about a well-known person that you admire and I'd like to discuss with you one or two more general questions Related to this. Okay. Let's consider first of all famous people in your country. Yeah What kind of people become famous in China? you know those actors especially the movie actors and the sports act sorry the movie actors and the sports stars They are very famous now in China because they can be seen by the people every day during the movie on the Advertisements they can be seen all the times So they are very famous and those people who are very rich and who has who had a really a big company and They can they are also you know on the TV on the news. So they are very famous as well What's different about people who were famous in the past with people who are famous these days? those I think those people who are very famous in the past are very great because they They do a lot to change the world. That's like Newton Einstein and you know, they found they found new logic. They found new new way about Building a building a new thing. So they are very famous but now the people who are very very famous just because of because only and they're very rich and the They act well and they do a really job about sports So I think now we just focus more on the real things but not the things before We just like the people who can who can who can do a great job and not to change the world now Is that a problem? I think in now in this way We Some somehow it can you know change the way of we see the world Especially to the children. Ah, this is just a movie stars is good a sports stars is good But they don't mind those scientists and maybe they just are in the future I just want to be a movie star and I just want to be a sports star But if all the children have to will do that we will act as a movie star who will change our world who will change Make our work better. So what kind of people may become famous in the future?\n",
      "\n",
      "SPEAKER SEPARATION (diarization):\n",
      "[SPEAKER_00] We've been talking about a well-known person that you admire and I'd like to discuss with you one or two more general questions Related to this. Okay. Let's consider first of all famous people in your country. Yeah What kind of people become famous in China?\n",
      "[SPEAKER_01] you know those actors especially the movie actors and the sports act sorry the movie actors and the sports stars They are very famous now in China because they can be seen by the people every day during the movie on the Advertisements they can be seen all the times So they are very famous and those people who are very rich and who has who had a really a big company and They can they are also you know on the TV on the news. So they are very famous as well\n",
      "[SPEAKER_00] What's different about people who were famous in the past with people who are famous these days?\n",
      "[SPEAKER_01] those I think those people who are very famous in the past are very great because they They do a lot to change the world. That's like Newton Einstein and you know, they found they found new logic. They found new new way about Building a building a new thing. So they are very famous but now the people who are very very famous just because of because only and they're very rich and the They act well and they do a really job about sports So I think now we just focus more on the real things but not the things before We just like the people who can who can who can do a great job and not to change the world now Is that a problem? I think in now in this way We Some somehow it can you know change the way of we see the world Especially to the children. Ah, this is just a movie stars is good a sports stars is good But they don't mind those scientists and maybe they just are in the future I just want to be a movie star and I just want to be a sports star But if all the children have to will do that we will act as a movie star who will change our world who will change Make our work better. So what kind of people may become famous in the future?\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Speech to Text (Whisper) + True Diarization\n",
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "import torch\n",
    "import torch.serialization as ts\n",
    "from torch.serialization import add_safe_globals\n",
    "from omegaconf import DictConfig, ListConfig\n",
    "from omegaconf.base import ContainerMetadata\n",
    "from typing import Any\n",
    "import warnings\n",
    "import io\n",
    "import contextlib\n",
    "import logging\n",
    "\n",
    "# Suppress noisy warnings from pyannote/torchaudio/torch\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Reduce library log noise\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pyannote\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"speechbrain\").setLevel(logging.ERROR)\n",
    "\n",
    "# Speed controls\n",
    "WHISPER_MODEL = \"medium\"\n",
    "WHISPER_BEAM_SIZE = 1\n",
    "WHISPER_VAD_FILTER = True\n",
    "\n",
    "use_cuda = True  # set True if GPU is available\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "compute_type = \"float16\" if use_cuda else \"int8\"\n",
    "\n",
    "model = WhisperModel(\n",
    "    WHISPER_MODEL,\n",
    "    device=device,\n",
    "    compute_type=compute_type,\n",
    ")\n",
    "\n",
    "segments, info = model.transcribe(\n",
    "    AUDIO_PATH,\n",
    "    beam_size=WHISPER_BEAM_SIZE,\n",
    "    vad_filter=WHISPER_VAD_FILTER,\n",
    ")\n",
    "segments = list(segments)\n",
    "\n",
    "transcript = \" \".join(s.text.strip() for s in segments)\n",
    "\n",
    "print(\"TRANSCRIPT:\")\n",
    "print(transcript)\n",
    "\n",
    "# True diarization using pyannote (requires HF_TOKEN)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\n",
    "        \"HF_TOKEN not set. Run the diarization setup cell, replace the token, \"\n",
    "        \"restart the kernel, then run this cell again.\"\n",
    "    )\n",
    "\n",
    "# Allow-list OmegaConf classes required by pyannote checkpoints\n",
    "add_safe_globals([DictConfig, ListConfig, ContainerMetadata, Any])\n",
    "\n",
    "# Reset torch.load to original, then wrap once to force weights_only=False\n",
    "if not hasattr(ts, \"_orig_load\"):\n",
    "    ts._orig_load = ts.load\n",
    "\n",
    "\n",
    "def _ts_load(*args, **kwargs):\n",
    "    kwargs[\"weights_only\"] = False\n",
    "    return ts._orig_load(*args, **kwargs)\n",
    "\n",
    "\n",
    "ts.load = _ts_load\n",
    "torch.load = ts.load\n",
    "\n",
    "# Reuse diarization pipeline across runs to avoid reload cost\n",
    "CACHE_DIR = os.environ.get(\"HF_HOME\") or os.path.join(os.getcwd(), \".hf_cache\")\n",
    "if \"_DIAR_PIPELINE\" not in globals():\n",
    "    _silence_out = io.StringIO()\n",
    "    with (\n",
    "        contextlib.redirect_stdout(_silence_out),\n",
    "        contextlib.redirect_stderr(_silence_out),\n",
    "    ):\n",
    "        from pyannote.audio import Pipeline\n",
    "\n",
    "        _DIAR_PIPELINE = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization\",\n",
    "            use_auth_token=HF_TOKEN,\n",
    "            cache_dir=CACHE_DIR,\n",
    "        )\n",
    "\n",
    "# Perform diarization on the audio file\n",
    "with (\n",
    "    contextlib.redirect_stdout(io.StringIO()),\n",
    "    contextlib.redirect_stderr(io.StringIO()),\n",
    "):\n",
    "    diarization = _DIAR_PIPELINE(AUDIO_PATH)\n",
    "\n",
    "# Map each whisper segment to the best overlapping speaker segment\n",
    "# to produce a speaker-labeled transcript.\n",
    "\n",
    "# Collect diarization segments\n",
    "_diars = []\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    _diars.append({\"start\": turn.start, \"end\": turn.end, \"speaker\": speaker})\n",
    "\n",
    "\n",
    "def _best_speaker_for_segment(seg_start, seg_end):\n",
    "    best_speaker = \"SPEAKER_00\"\n",
    "    best_overlap = 0.0\n",
    "    for d in _diars:\n",
    "        overlap = max(0.0, min(seg_end, d[\"end\"]) - max(seg_start, d[\"start\"]))\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_speaker = d[\"speaker\"]\n",
    "    return best_speaker\n",
    "\n",
    "\n",
    "# Merge consecutive segments with the same speaker\n",
    "merged = []\n",
    "current_speaker = None\n",
    "current_text = []\n",
    "for s in segments:\n",
    "    speaker = _best_speaker_for_segment(s.start, s.end)\n",
    "    text = s.text.strip()\n",
    "    if speaker == current_speaker:\n",
    "        current_text.append(text)\n",
    "    else:\n",
    "        if current_speaker is not None:\n",
    "            merged.append((current_speaker, \" \".join(current_text)))\n",
    "        current_speaker = speaker\n",
    "        current_text = [text]\n",
    "if current_speaker is not None:\n",
    "    merged.append((current_speaker, \" \".join(current_text)))\n",
    "\n",
    "speaker_separated = \"\\n\".join(f\"[{speaker}] {text}\" for speaker, text in merged)\n",
    "print(\"\\nSPEAKER SEPARATION (diarization):\")\n",
    "print(speaker_separated)\n",
    "\n",
    "# Set use_cuda=True if using GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
