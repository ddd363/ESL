{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b603bf",
   "metadata": {},
   "source": [
    "# ESL Speech Analysis (Remote Kernel)\n",
    "\n",
    "**Assumptions**\n",
    "- Recording happens locally.\n",
    "- Audio is uploaded as .wav (16 kHz preferred) or .m4a (converted to .wav).\n",
    "- Notebook runs on Paperspace (CPU or GPU).\n",
    "- No microphone access.\n",
    "- .m4a conversion requires ffmpeg available in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74048cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53791366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faster-whisper in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
      "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (3.2.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (4.15.0)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.6.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.15.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (1.23.2)\n",
      "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (16.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.66.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (2.31.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (5.9.8)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (69.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/lib/python3/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (5.4.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2023.6.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.23.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python) (2.0.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Cell 0: Environment Setup (run once)\n",
    "# For .m4a support, pydub needs ffmpeg available in the runtime.\n",
    "!pip install faster-whisper language-tool-python pydub openai -U typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bb8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.6.1 requires typer<0.10.0,>=0.3.0, but you have typer 0.21.1 which is incompatible.\n",
      "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 6.33.4 which is incompatible.\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 6.33.4 which is incompatible.\n",
      "torchvision 0.16.1+cu121 requires torch==2.1.1, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mHF_TOKEN set for this session.\n"
     ]
    }
   ],
   "source": [
    "# Cell 0b: Diarization Setup (run once)\n",
    "# Installs pyannote and pins NumPy to avoid ABI issues with pyarrow/pandas.\n",
    "# After running this cell, restart the kernel, then run it again.\n",
    "!pip install -q \"numpy<2\" \"pandas<2.2\" \"pyarrow<16\" pyannote.audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903eb591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN set for this session.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "print(\"HF_TOKEN set for this session.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e92c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b27253a5aa4bb484405b456abfe84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.wav,.m4a', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# FileUpload widget (in-memory)\n",
    "upload = widgets.FileUpload(accept=\".wav,.m4a\", multiple=False)\n",
    "display(upload)\n",
    "\n",
    "# Global variable to hold the audio content\n",
    "AUDIO_BYTES = None\n",
    "AUDIO_FILENAME = None\n",
    "\n",
    "\n",
    "def _iter_uploaded_files(value):\n",
    "    # ipywidgets can return dict-like (v7) or tuple/list (v8)\n",
    "    if hasattr(value, \"items\"):\n",
    "        for name, file_info in value.items():\n",
    "            yield name, file_info\n",
    "    elif isinstance(value, (list, tuple)):\n",
    "        for file_info in value:\n",
    "            name = file_info.get(\"name\") if isinstance(file_info, dict) else None\n",
    "            yield name, file_info\n",
    "\n",
    "\n",
    "def store_audio(change):\n",
    "    global AUDIO_BYTES, AUDIO_FILENAME\n",
    "    if not upload.value:\n",
    "        return\n",
    "    for name, file_info in _iter_uploaded_files(upload.value):\n",
    "        if isinstance(file_info, dict):\n",
    "            AUDIO_BYTES = file_info.get(\"content\")\n",
    "            AUDIO_FILENAME = name or file_info.get(\"name\")\n",
    "            if AUDIO_BYTES and AUDIO_FILENAME:\n",
    "                print(\n",
    "                    f\"Audio file '{AUDIO_FILENAME}' is now ready in memory for other cells.\"\n",
    "                )\n",
    "\n",
    "\n",
    "# Automatically trigger when a file is uploaded\n",
    "upload.observe(store_audio, names=\"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f97ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file loaded from upload: audio/20260119 102010.wav\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load most recent audio file from ./audio (.wav or .m4a)\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AUDIO_DIR = \"audio\"\n",
    "SUPPORTED_EXTS = {\".wav\", \".m4a\"}\n",
    "\n",
    "# Prefer in-memory upload if present\n",
    "if \"AUDIO_BYTES\" in globals() and AUDIO_BYTES and AUDIO_FILENAME:\n",
    "    ext = os.path.splitext(AUDIO_FILENAME)[1].lower()\n",
    "    if ext not in SUPPORTED_EXTS:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.join(\n",
    "            AUDIO_DIR, os.path.splitext(AUDIO_FILENAME)[0] + \".wav\"\n",
    "        )\n",
    "        audio = AudioSegment.from_file(io.BytesIO(AUDIO_BYTES), format=\"m4a\")\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    else:\n",
    "        AUDIO_PATH = os.path.join(AUDIO_DIR, AUDIO_FILENAME)\n",
    "        with open(AUDIO_PATH, \"wb\") as f:\n",
    "            f.write(AUDIO_BYTES)\n",
    "\n",
    "    print(f\"Audio file loaded from upload: {AUDIO_PATH}\")\n",
    "else:\n",
    "    if not os.path.isdir(AUDIO_DIR):\n",
    "        raise FileNotFoundError(f\"Directory not found: {AUDIO_DIR}\")\n",
    "\n",
    "    candidates = [\n",
    "        os.path.join(AUDIO_DIR, f)\n",
    "        for f in os.listdir(AUDIO_DIR)\n",
    "        if os.path.splitext(f)[1].lower() in SUPPORTED_EXTS\n",
    "        and os.path.isfile(os.path.join(AUDIO_DIR, f))\n",
    "    ]\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"No .wav or .m4a files found in ./audio. Add a file and try again.\"\n",
    "        )\n",
    "\n",
    "    INPUT_PATH = max(candidates, key=os.path.getmtime)\n",
    "\n",
    "    ext = os.path.splitext(INPUT_PATH)[1].lower()\n",
    "\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.splitext(INPUT_PATH)[0] + \".wav\"\n",
    "        audio = AudioSegment.from_file(INPUT_PATH, format=\"m4a\")\n",
    "        # Convert to mono/16k for best Whisper results\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    elif ext == \".wav\":\n",
    "        AUDIO_PATH = INPUT_PATH\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    print(f\"Audio file loaded: {AUDIO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b93aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSCRIPT:\n",
      "We've been talking about a well-known person that you admire and I'd like to discuss with you one or two more general questions related to this. Let's consider first of all famous people in your country. What kind of people become famous in China? Those actors, especially the movie actors and the sports actors, sorry, the movie actors and the sports stars, they are very famous now in China because they can be seen by the people every day during the movie on the advertisements, they can be seen all the times. So they are very famous and those people who are very rich and who had a really big company and they are also on the TV, on the news, so they are very famous as well. What's different about people who were famous in the past with people who are famous these days? I think those people who were very famous in the past are very great because they do a lot to change the world, just like Newton Einstein and they found new logics, they found new way about building a new thing, so they are very famous. And now the people who are very famous just because they are very rich and they act well and they do a really good job about sports. So I think now we just focus more on the real things but not the things before. We just like the people who can do a great job but not to change the world now. Is that a problem? I think now in this way somehow it can change the way we see the world, especially to the children. They say just movie stars is good, sports stars is good, but they don't mind those scientists and maybe in the future I just want to be a movie star and I just want to be a sports star. If all the children will do that, will act as a movie star, who will change our world, who will make our world better? So what kind of people may become famous in the future?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.11/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 531, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_348/4131444807.py\", line 35, in <module>\n",
      "    from pyannote.audio import Pipeline\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/__init__.py\", line 28, in <module>\n",
      "    from .core.inference import Inference\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/inference.py\", line 34, in <module>\n",
      "    from pyannote.audio.core.model import Model, Specifications\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/model.py\", line 43, in <module>\n",
      "    from pyannote.audio.core.task import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/task.py\", line 46, in <module>\n",
      "    from pyannote.audio.utils.protocol import check_protocol\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/utils/protocol.py\", line 28, in <module>\n",
      "    from pyannote.database import FileFinder, Protocol, get_annotated\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/__init__.py\", line 36, in <module>\n",
      "    from .registry import registry, LoadingMode\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/registry.py\", line 38, in <module>\n",
      "    from .custom import create_protocol, get_init\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/custom.py\", line 65, in <module>\n",
      "    from .util import get_annotated\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/util.py\", line 32, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pandas/compat/__init__.py\", line 29, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 542, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 531, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 775, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_348/4131444807.py\", line 35, in <module>\n",
      "    from pyannote.audio import Pipeline\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/__init__.py\", line 28, in <module>\n",
      "    from .core.inference import Inference\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/inference.py\", line 34, in <module>\n",
      "    from pyannote.audio.core.model import Model, Specifications\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/model.py\", line 43, in <module>\n",
      "    from pyannote.audio.core.task import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/core/task.py\", line 46, in <module>\n",
      "    from pyannote.audio.utils.protocol import check_protocol\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/audio/utils/protocol.py\", line 28, in <module>\n",
      "    from pyannote.database import FileFinder, Protocol, get_annotated\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/__init__.py\", line 36, in <module>\n",
      "    from .registry import registry, LoadingMode\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/registry.py\", line 38, in <module>\n",
      "    from .custom import create_protocol, get_init\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/custom.py\", line 65, in <module>\n",
      "    from .util import get_annotated\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyannote/database/util.py\", line 32, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization failed: Pipeline.from_pretrained() got an unexpected keyword argument 'use_auth_token'\n",
      "\n",
      "SPEAKER SEPARATION (heuristic):\n",
      "[speaker 1] We've been talking about a well-known person that you admire and I'd like to discuss with you one or two more general questions related to this.\n",
      "[speaker 1] Let's consider first of all famous people in your country.\n",
      "[speaker 1] What kind of people become famous in China?\n",
      "[speaker 2] Those actors, especially the movie actors and the sports actors, sorry, the movie actors and the sports stars, they are very famous now in China because they can be seen by the people every day during the movie on the advertisements, they can be seen all the times.\n",
      "[speaker 2] So they are very famous and those people who are very rich and who had a really big company and they are also on the TV, on the news, so they are very famous as well.\n",
      "[speaker 2] What's different about people who were famous in the past with people who are famous these days?\n",
      "[speaker 2] I think those people who were very famous in the past are very great because they do a lot to change the world, just like Newton Einstein and they found new logics, they found new way about building a new thing, so they are very famous.\n",
      "[speaker 2] And now the people who are very famous just because they are very rich and they act well and they do a really good job about sports.\n",
      "[speaker 2] So I think now we just focus more on the real things but not the things before.\n",
      "[speaker 2] We just like the people who can do a great job but not to change the world now.\n",
      "[speaker 2] Is that a problem?\n",
      "[speaker 2] I think now in this way somehow it can change the way we see the world, especially to the children.\n",
      "[speaker 2] They say just movie stars is good, sports stars is good, but they don't mind those scientists and maybe in the future I just want to be a movie star and I just want to be a sports star.\n",
      "[speaker 2] If all the children will do that, will act as a movie star, who will change our world, who will make our world better?\n",
      "[speaker 2] So what kind of people may become famous in the future?\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Speech to Text (Whisper) + True Diarization\n",
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "\n",
    "use_cuda = True  # set True if GPU is available\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "compute_type = \"float16\" if use_cuda else \"int8\"\n",
    "\n",
    "model = WhisperModel(\n",
    "    \"medium\",\n",
    "    device=device,\n",
    "    compute_type=compute_type,\n",
    ")\n",
    "\n",
    "segments, info = model.transcribe(AUDIO_PATH)\n",
    "segments = list(segments)\n",
    "\n",
    "transcript = \" \".join(s.text.strip() for s in segments)\n",
    "\n",
    "print(\"TRANSCRIPT:\")\n",
    "print(transcript)\n",
    "\n",
    "# True diarization using pyannote (requires HF_TOKEN)\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise RuntimeError(\n",
    "        \"HF_TOKEN not set. Run the diarization setup cell and restart the kernel.\"\n",
    "    )\n",
    "\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization\",\n",
    "    use_auth_token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "# Perform diarization on the audio file\n",
    "diarization = pipeline(AUDIO_PATH)\n",
    "\n",
    "# Map each whisper segment to the best overlapping speaker segment\n",
    "# to produce a speaker-labeled transcript.\n",
    "\n",
    "# Collect diarization segments\n",
    "_diars = []\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    _diars.append({\"start\": turn.start, \"end\": turn.end, \"speaker\": speaker})\n",
    "\n",
    "\n",
    "def _best_speaker_for_segment(seg_start, seg_end):\n",
    "    best_speaker = \"SPEAKER_00\"\n",
    "    best_overlap = 0.0\n",
    "    for d in _diars:\n",
    "        overlap = max(0.0, min(seg_end, d[\"end\"]) - max(seg_start, d[\"start\"]))\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_speaker = d[\"speaker\"]\n",
    "    return best_speaker\n",
    "\n",
    "\n",
    "labeled_lines = []\n",
    "for s in segments:\n",
    "    speaker = _best_speaker_for_segment(s.start, s.end)\n",
    "    labeled_lines.append(f\"[{speaker}] {s.text.strip()}\")\n",
    "\n",
    "speaker_separated = \"\\n\".join(labeled_lines)\n",
    "print(\"\\nSPEAKER SEPARATION (diarization):\")\n",
    "print(speaker_separated)\n",
    "\n",
    "# Set use_cuda=True if using GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db067a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESL ISSUES:\n",
      "\n",
      "- Using “interest or hobby” is awkward and unclear; choose one and match singular/plural with the list that follows.\n",
      "  Context: My interest or hobby that I enjoy is shopping and picnics\n",
      "  Suggestion: My hobbies are shopping and having picnics.\n",
      "\n",
      "- The sentence has too many ideas joined by commas, which makes it hard to follow.\n",
      "  Context: ..., to spend time with my family or friends, or especially I want to do volunteer for shopping.\n",
      "  Suggestion: Break into shorter sentences or use clearer connectors.\n",
      "\n",
      "- “Do volunteer” is incorrect; use “do volunteer work” or “volunteer.”\n",
      "  Context: I want to do volunteer for shopping\n",
      "  Suggestion: I especially want to do volunteer work related to shopping. / I want to volunteer.\n",
      "\n",
      "- “Volunteer for shopping” is unclear (volunteer to shop? volunteer at a charity?).\n",
      "  Context: ...volunteer for shopping\n",
      "  Suggestion: Say what you mean: “volunteer at a charity shop,” “help people shop,” or “collect donations.”\n",
      "\n",
      "- After “can,” use the base form of the verb (“shop”), not “shopping.”\n",
      "  Context: I can shopping\n",
      "  Suggestion: I can shop.\n",
      "\n",
      "- Repetition and comma splices make the structure uneven; the ideas need clearer connection.\n",
      "  Context: I think when I feel stressed out, I can shopping, I can relax...\n",
      "  Suggestion: When I feel stressed out, I can shop and relax.\n",
      "\n",
      "- Use “some new clothes” (plural) or “a new item of clothing” (singular). Also remove “a” before plural “clothes.”\n",
      "  Context: buy a new clothes\n",
      "  Suggestion: buy some new clothes / buy a new outfit.\n",
      "\n",
      "- “Relax to buy” is unnatural; use “by buying” or restructure the sentence.\n",
      "  Context: I can relax to buy a new clothes\n",
      "  Suggestion: I can relax by buying some new clothes.\n",
      "\n",
      "- “In the special days” is unnatural; use “on special days” or “for special occasions.”\n",
      "  Context: in the special days\n",
      "  Suggestion: on special days / for special occasions.\n",
      "\n",
      "- Use “on picnics” or “during picnics,” not “in picnics.”\n",
      "  Context: And in picnics and travel\n",
      "  Suggestion: On picnics and when I travel...\n",
      "\n",
      "- “Picnics and travel” mixes a plural noun with an uncountable noun; use parallel forms.\n",
      "  Context: picnics and travel\n",
      "  Suggestion: picnics and traveling / going on picnics and traveling.\n",
      "\n",
      "- Repeated “I think” and “especially” weakens clarity; vary phrasing or remove repetition.\n",
      "  Context: I think... I think... and especially...\n",
      "  Suggestion: Remove some “I think” and keep “especially” only where needed.\n",
      "\n",
      "- “Spend time to understand them” is better as “spend time with them” or “spend time getting to know them.”\n",
      "  Context: I can spend time to understand them\n",
      "  Suggestion: I can spend time with them and understand them better.\n",
      "\n",
      "- “The most important” needs a noun (“thing/activity”).\n",
      "  Context: the most important is to volunteer\n",
      "  Suggestion: the most important thing for me is volunteering.\n",
      "\n",
      "- Use the gerund for activities: “volunteering,” not “to volunteer.”\n",
      "  Context: ...is to volunteer\n",
      "  Suggestion: ...is volunteering.\n",
      "\n",
      "- “Because I love, actually I love the people” is awkward and incorrectly punctuated.\n",
      "  Context: because I love, actually I love the people\n",
      "  Suggestion: because I really love people.\n",
      "\n",
      "- “the people” is too general; “people” works better, or specify a group.\n",
      "  Context: I love the people\n",
      "  Suggestion: I love people / I love helping others.\n",
      "\n",
      "- “Spend time to help” is better as “spend time helping.”\n",
      "  Context: spend time to help them\n",
      "  Suggestion: spend time helping them.\n",
      "\n",
      "- “Overcome or try to get over the problem” is repetitive; choose one phrase and use plural if general.\n",
      "  Context: overcome or try to get over the problem\n",
      "  Suggestion: overcome their problems / get over their problems.\n",
      "\n",
      "- “So I often, before when I live in Vietnam” has incorrect word order and tense. Use past tense if this is a past habit.\n",
      "  Context: So I often, before when I live in Vietnam, I often go\n",
      "  Suggestion: When I lived in Vietnam, I often went...\n",
      "\n",
      "- The paragraph shifts between present and past; keep past tense for actions in Vietnam.\n",
      "  Context: I often go to the church... I often ask...\n",
      "  Suggestion: I often went... I often asked...\n",
      "\n",
      "- “Church” usually needs an article or possessive (“the church,” “a church,” “my church”).\n",
      "  Context: go to the church or some association\n",
      "  Suggestion: go to a church / go to my church / go to the church.\n",
      "\n",
      "- “Some association” is vague; “an organization/charity” is clearer.\n",
      "  Context: some association\n",
      "  Suggestion: a local charity / an organization.\n",
      "\n",
      "- “Contribute and give a hand to help” is wordy and repetitive; choose one clear structure.\n",
      "  Context: contribute and give a hand to help\n",
      "  Suggestion: donate and help / contribute and help.\n",
      "\n",
      "- “Old people” is understandable but can sound impolite; “elderly people/older people/seniors” is more respectful.\n",
      "  Context: the old people\n",
      "  Suggestion: elderly people / older people.\n",
      "\n",
      "- The sentence is very long with multiple clauses joined by commas; it needs splitting and clearer connectors.\n",
      "  Context: ..., because I think the old people also, it looks like my grandparents, so I want to take care of them.\n",
      "  Suggestion: Split: “Because older people remind me of my grandparents, I want to take care of them.”\n",
      "\n",
      "- “The old people... it looks like” has pronoun mismatch (plural “people” vs singular “it”).\n",
      "  Context: the old people also, it looks like my grandparents\n",
      "  Suggestion: Older people remind me of my grandparents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: ESL Error Detection (OpenAI via HTTP)\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "OPENAI_MODEL = \"gpt-5.2\"\n",
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "def get_issue_type(match):\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"type\", \"UNKNOWN\")\n",
    "    if hasattr(match, \"ruleId\"):\n",
    "        return match.ruleId\n",
    "    if hasattr(match, \"rule_id\"):\n",
    "        return match.rule_id\n",
    "    if hasattr(match, \"rule\"):\n",
    "        rule = match.rule\n",
    "        if isinstance(rule, dict) and \"id\" in rule:\n",
    "            return rule[\"id\"]\n",
    "        if hasattr(rule, \"id\"):\n",
    "            return rule.id\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    print(\"OPENAI_API_KEY not set. Set it to enable OpenAI-based ESL checks.\")\n",
    "    matches = []\n",
    "else:\n",
    "    system_msg = (\n",
    "        \"You are an ESL writing assistant. Identify grammar and usage errors in the transcript. \"\n",
    "        \"Return a JSON object with an array 'issues'. Each issue must include: \"\n",
    "        \"type (short label), message (explain the error), context (short excerpt), suggestion (optional).\"\n",
    "    )\n",
    "    user_msg = f\"Transcript:\\n{transcript}\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"issues\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"type\": {\"type\": \"string\"},\n",
    "                        \"message\": {\"type\": \"string\"},\n",
    "                        \"context\": {\"type\": \"string\"},\n",
    "                        \"suggestion\": {\"type\": \"string\"},\n",
    "                    },\n",
    "                    \"required\": [\"type\", \"message\", \"context\", \"suggestion\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"issues\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": OPENAI_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"name\": \"esl_issues\", \"schema\": schema, \"strict\": True},\n",
    "        },\n",
    "    }\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=payload,\n",
    "        timeout=60,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    resp = r.json()\n",
    "\n",
    "    if \"choices\" in resp and len(resp[\"choices\"]) > 0:\n",
    "        content_str = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        data = json.loads(content_str)\n",
    "        matches = data.get(\"issues\", [])\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unexpected response format from OpenAI: {json.dumps(resp, indent=2)}\"\n",
    "        )\n",
    "\n",
    "print(\"ESL ISSUES:\\n\")\n",
    "for m in matches:\n",
    "    if isinstance(m, dict):\n",
    "        print(f\"- {m.get('message', '')}\")\n",
    "        print(f\"  Context: {m.get('context', '')}\")\n",
    "        if m.get(\"suggestion\"):\n",
    "            print(f\"  Suggestion: {m.get('suggestion')}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"- {m.message}\")\n",
    "        print(f\"  Context: {m.context}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "717e8a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR SUMMARY:\n",
      "\n",
      "grammar: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Clean Teacher-Friendly Summary\n",
    "from collections import Counter\n",
    "\n",
    "error_types = Counter(get_issue_type(m) for m in matches)\n",
    "\n",
    "print(\"ERROR SUMMARY:\\n\")\n",
    "for rule, count in error_types.most_common():\n",
    "    print(f\"{rule}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e41eefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved analysis_results.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 (Optional): Save Results\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    \"transcript\": transcript,\n",
    "    \"errors\": [\n",
    "        {\n",
    "            \"message\": (m.get(\"message\") if isinstance(m, dict) else m.message),\n",
    "            \"context\": (m.get(\"context\") if isinstance(m, dict) else m.context),\n",
    "            \"rule\": get_issue_type(m),\n",
    "            \"suggestion\": (m.get(\"suggestion\") if isinstance(m, dict) else None),\n",
    "        }\n",
    "        for m in matches\n",
    "    ],\n",
    "}\n",
    "\n",
    "with open(\"analysis_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Saved analysis_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1333b",
   "metadata": {},
   "source": [
    "## Why This Notebook Design Works\n",
    "- Fully compatible with remote kernels.\n",
    "- Deterministic and reproducible.\n",
    "- Easy to iterate on analysis logic.\n",
    "- Clean separation of concerns: Capture, Transcription, Analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
