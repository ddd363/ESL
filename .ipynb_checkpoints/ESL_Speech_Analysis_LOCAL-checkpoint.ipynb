{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b603bf",
   "metadata": {},
   "source": [
    "# ESL Speech Analysis (Remote Kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53791366",
   "metadata": {},
   "source": [
    "# Cell 0: Environment Setup (run once)\n",
    "# For .m4a support, pydub needs ffmpeg available in the runtime.\n",
    "!pip install faster-whisper language-tool-python pydub openai replicate -U typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e92c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d12d8783b0d47a0b6d62ad0917ea398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.wav,.m4a', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# FileUpload widget (in-memory)\n",
    "upload = widgets.FileUpload(accept=\".wav,.m4a\", multiple=False)\n",
    "display(upload)\n",
    "\n",
    "# Global variable to hold the audio content\n",
    "AUDIO_BYTES = None\n",
    "AUDIO_FILENAME = None\n",
    "\n",
    "\n",
    "def _iter_uploaded_files(value):\n",
    "    # ipywidgets can return dict-like (v7) or tuple/list (v8)\n",
    "    if hasattr(value, \"items\"):\n",
    "        for name, file_info in value.items():\n",
    "            yield name, file_info\n",
    "    elif isinstance(value, (list, tuple)):\n",
    "        for file_info in value:\n",
    "            name = file_info.get(\"name\") if isinstance(file_info, dict) else None\n",
    "            yield name, file_info\n",
    "\n",
    "\n",
    "def store_audio(change):\n",
    "    global AUDIO_BYTES, AUDIO_FILENAME\n",
    "    if not upload.value:\n",
    "        return\n",
    "    for name, file_info in _iter_uploaded_files(upload.value):\n",
    "        if isinstance(file_info, dict):\n",
    "            AUDIO_BYTES = file_info.get(\"content\")\n",
    "            AUDIO_FILENAME = name or file_info.get(\"name\")\n",
    "            if AUDIO_BYTES and AUDIO_FILENAME:\n",
    "                print(\n",
    "                    f\"Audio file '{AUDIO_FILENAME}' is now ready in memory for other cells.\"\n",
    "                )\n",
    "\n",
    "\n",
    "# Automatically trigger when a file is uploaded\n",
    "upload.observe(store_audio, names=\"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9664cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file loaded from upload: audio/famous people.wav\n",
      "HUMAN-READABLE DIARIZATION:\n",
      "\n",
      "[SPEAKER_01] 00:01.95–00:12.91: We've been talking about a well-known person that you admire, and I'd like to discuss with you one or two more general questions related to this. Let's consider, first of all, famous people in your country.\n",
      "[SPEAKER_00] 00:13.15–00:13.55: Yeah.\n",
      "[SPEAKER_01] 00:15.05–00:17.33: What kind of people become famous in China?\n",
      "[SPEAKER_00] 00:18.21–00:48.01: You know, those actors, especially the movie actors and the sports stars, they are very famous now in China because they can be seen by the people every day during the movie on the advertisements. They can be seen all the times, so they are very famous. And those people who are very rich and who have a really big company, they are also on the TV, on the news, so they are very famous as well.\n",
      "[SPEAKER_01] 00:48.99–00:53.99: What's different about people who were famous in the past with people who are famous these days?\n",
      "[SPEAKER_00] 00:55.01–02:19.10: Those, I think, those people who are very famous in the past are very great because they do a lot to change the world, just like Newton, Einstein, and, you know, they find new logics, they find new way about building a new thing, so they are very famous. But now the people who are very famous just because only they are very rich and they act well and they do a really job about sports. So I think now we just focus more on the real things but not the things before. We just like the people who can do a great job but not to change the world now. Is that a problem? Well, I think now in this way somehow it can, you know, change the way of we see the world, especially to the children. They say just movie stars is good, sports stars is good, but they do not mind those scientists and maybe they just, in the future I just want to be a movie star and I just want to be a sports star. But if all the children will do that, we will act as a movie star, who will change our world, who will change, make our world better. So that's it.\n",
      "[SPEAKER_01] 02:19.86–02:23.22: So what kind of people may become famous in the future?\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load most recent audio file from ./audio (.wav or .m4a)\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AUDIO_DIR = \"audio\"\n",
    "SUPPORTED_EXTS = {\".wav\", \".m4a\"}\n",
    "\n",
    "# Prefer in-memory upload if present\n",
    "if \"AUDIO_BYTES\" in globals() and AUDIO_BYTES and AUDIO_FILENAME:\n",
    "    ext = os.path.splitext(AUDIO_FILENAME)[1].lower()\n",
    "    if ext not in SUPPORTED_EXTS:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.join(\n",
    "            AUDIO_DIR, os.path.splitext(AUDIO_FILENAME)[0] + \".wav\"\n",
    "        )\n",
    "        audio = AudioSegment.from_file(io.BytesIO(AUDIO_BYTES), format=\"m4a\")\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    else:\n",
    "        AUDIO_PATH = os.path.join(AUDIO_DIR, AUDIO_FILENAME)\n",
    "        with open(AUDIO_PATH, \"wb\") as f:\n",
    "            f.write(AUDIO_BYTES)\n",
    "\n",
    "    print(f\"Audio file loaded from upload: {AUDIO_PATH}\")\n",
    "else:\n",
    "    if not os.path.isdir(AUDIO_DIR):\n",
    "        raise FileNotFoundError(f\"Directory not found: {AUDIO_DIR}\")\n",
    "\n",
    "    candidates = [\n",
    "        os.path.join(AUDIO_DIR, f)\n",
    "        for f in os.listdir(AUDIO_DIR)\n",
    "        if os.path.splitext(f)[1].lower() in SUPPORTED_EXTS\n",
    "        and os.path.isfile(os.path.join(AUDIO_DIR, f))\n",
    "    ]\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"No .wav or .m4a files found in ./audio. Add a file and try again.\"\n",
    "        )\n",
    "\n",
    "    INPUT_PATH = max(candidates, key=os.path.getmtime)\n",
    "\n",
    "    ext = os.path.splitext(INPUT_PATH)[1].lower()\n",
    "\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.splitext(INPUT_PATH)[0] + \".wav\"\n",
    "        audio = AudioSegment.from_file(INPUT_PATH, format=\"m4a\")\n",
    "        # Convert to mono/16k for best Whisper results\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    elif ext == \".wav\":\n",
    "        AUDIO_PATH = INPUT_PATH\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    print(f\"Audio file loaded: {AUDIO_PATH}\")\n",
    "\n",
    "\n",
    "# Cell 0c: Replicate diarization (Whisper + diarization as a service)\n",
    "# Put your Replicate API key here (or set in environment before running):\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_UdBzdYuIUsDW5MWGvuvgchX7FrxJvho3Vj88j\"\n",
    "\n",
    "import os\n",
    "import replicate\n",
    "\n",
    "# Ensure audio is prepared (run Cell 1 first to set AUDIO_PATH)\n",
    "if \"AUDIO_PATH\" not in globals():\n",
    "    raise RuntimeError(\"AUDIO_PATH not set. Run the audio load cell first.\")\n",
    "\n",
    "if not os.environ.get(\"REPLICATE_API_TOKEN\"):\n",
    "    raise RuntimeError(\"REPLICATE_API_TOKEN not set. Add it in this cell and re-run.\")\n",
    "\n",
    "# Replicate diarization settings\n",
    "NUM_SPEAKERS = 2  # set to None to autodetect\n",
    "GROUP_SEGMENTS = True  # merge short same-speaker segments\n",
    "\n",
    "# Run diarization on Replicate (pin to a model version)\n",
    "\n",
    "model_id = \"thomasmol/whisper-diarization:1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886\"\n",
    "with open(AUDIO_PATH, \"rb\") as f:\n",
    "    input_payload = {\n",
    "        \"file\": f,\n",
    "        \"output\": \"json\",\n",
    "        \"group_segments\": GROUP_SEGMENTS,\n",
    "    }\n",
    "    if NUM_SPEAKERS:\n",
    "        input_payload[\"num_speakers\"] = NUM_SPEAKERS\n",
    "    replicate_output = replicate.run(\n",
    "        model_id,\n",
    "        input=input_payload,\n",
    "    )\n",
    "\n",
    "# Save results for downstream use\n",
    "REPLICATE_DIARIZATION = replicate_output\n",
    "\n",
    "# print(\"Replicate diarization output:\")\n",
    "# print(replicate_output)\n",
    "\n",
    "\n",
    "# Cell 2: Human-readable diarization output (from Replicate)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def _format_time(sec):\n",
    "    m = int(sec // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{m:02d}:{s:05.2f}\"\n",
    "\n",
    "\n",
    "def _normalize_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = re.sub(r\"[\\W_]+\", \"\", t)\n",
    "    return t\n",
    "\n",
    "\n",
    "def _dedupe_sentences(text):\n",
    "    # Remove consecutive duplicate sentences after splitting on punctuation\n",
    "    parts = re.split(r\"(?<=[.!?])\\s+\", text.strip())\n",
    "    out = []\n",
    "    last_norm = None\n",
    "    for p in parts:\n",
    "        if not p:\n",
    "            continue\n",
    "        norm = _normalize_text(p)\n",
    "        if norm and norm == last_norm:\n",
    "            continue\n",
    "        out.append(p)\n",
    "        last_norm = norm\n",
    "    return \" \".join(out)\n",
    "\n",
    "\n",
    "def _merge_segments(segments):\n",
    "    merged = []\n",
    "    last_text_norm = None\n",
    "    for seg in segments:\n",
    "        speaker = seg.get(\"speaker\") or \"UNKNOWN\"\n",
    "        text = (seg.get(\"text\") or \"\").strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        start = seg.get(\"start\", 0.0)\n",
    "        end = seg.get(\"end\", 0.0)\n",
    "        # If speaker is UNKNOWN, stick with previous speaker when possible\n",
    "        if speaker == \"UNKNOWN\" and merged:\n",
    "            speaker = merged[-1][\"speaker\"]\n",
    "        text = _dedupe_sentences(text)\n",
    "        text_norm = _normalize_text(text)\n",
    "        if text_norm and text_norm == last_text_norm:\n",
    "            # Skip exact repeat chunk\n",
    "            continue\n",
    "        if merged and merged[-1][\"speaker\"] == speaker:\n",
    "            # Merge consecutive same-speaker chunks\n",
    "            merged[-1][\"end\"] = end\n",
    "            merged[-1][\"text\"] += \" \" + text\n",
    "        else:\n",
    "            merged.append(\n",
    "                {\"speaker\": speaker, \"start\": start, \"end\": end, \"text\": text}\n",
    "            )\n",
    "        last_text_norm = text_norm\n",
    "    return merged\n",
    "\n",
    "\n",
    "def _pretty_print_replicate(output):\n",
    "    if not output:\n",
    "        print(\n",
    "            \"No Replicate output available. Run the Replicate diarization cell first.\"\n",
    "        )\n",
    "        return\n",
    "    # Replicate returns a dict with `segments` or a list in some cases\n",
    "    segments = None\n",
    "    if isinstance(output, dict):\n",
    "        segments = output.get(\"segments\")\n",
    "    elif isinstance(output, list):\n",
    "        segments = output\n",
    "    if not segments:\n",
    "        print(\"No segments found in Replicate output.\")\n",
    "        return\n",
    "    merged = _merge_segments(segments)\n",
    "    if not merged:\n",
    "        print(\"No usable segments after merging.\")\n",
    "        return\n",
    "    print(\"HUMAN-READABLE DIARIZATION:\\n\")\n",
    "    last_speaker = None\n",
    "    for seg in merged:\n",
    "        speaker = seg[\"speaker\"]\n",
    "        start = _format_time(seg.get(\"start\", 0.0))\n",
    "        end = _format_time(seg.get(\"end\", 0.0))\n",
    "        text = seg[\"text\"]\n",
    "        if speaker != last_speaker:\n",
    "            print(f\"[{speaker}] {start}–{end}: {text}\")\n",
    "            last_speaker = speaker\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "\n",
    "# Use saved output from the Replicate cell\n",
    "_pretty_print_replicate(globals().get(\"REPLICATE_DIARIZATION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db067a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESL ISSUES:\n",
      "\n",
      "- On-the-Fly Feedback Table (Speaker 00)\n",
      "\n",
      "| Error Group (sorted from highest to lowest IELTS impact) | Student Examples (exact phrases from transcript) | Better Versions | Explanation (clear, teacher-ready, 1–2 short lines) |\n",
      "|---|---|---|---|\n",
      "| Coherence / clause structure / logic | \"I think sometimes people need some casual social life that if they have a hobby actually they could probably\" | \"I think people sometimes want a casual social life, and having a hobby can help.\" | The sentence structure is tangled (\"that if...\") and weakens clarity and coherence. |\n",
      "| Coherence / clause structure / logic | \"Actually everyone could do it because as we know it's very expensive\" | \"Actually, not everyone can do it because, as we know, it’s very expensive.\" | Logical connector is wrong (\"everyone could\" conflicts with \"very expensive\"). |\n",
      "| Coherence / clause structure / logic | \"if he really addicted to a sports car\" | \"if he’s really addicted to sports cars\" | Missing verb \"is/’s\" and unclear noun use reduce clarity. |\n",
      "| Coherence / clause structure / logic | \"forget what happened for the day walk\" | \"forget what happened during the day\" | The ending phrase is not logical/clear, so meaning is hard to follow. |\n",
      "| Collocation and word choice | \"connect stamp\" | \"collect stamps\" | Wrong verb for the activity; \"collect\" is the natural collocation. |\n",
      "| Collocation and word choice | \"connect a sports car\" | \"collect sports cars\" | Wrong verb choice; \"connect\" doesn’t match this meaning. |\n",
      "| Collocation and word choice | \"share the feeling\" | \"share their feelings\" / \"share the experience\" | \"share the feeling\" is unnatural here; use plural \"feelings\" or \"experience.\" |\n",
      "| Fixed phrases / prepositions | \"what kind of hobbies to have\" | \"what kind of hobbies they have\" | In a statement, use subject + verb order, not an infinitive structure. |\n",
      "| Fixed phrases / prepositions | \"spend a lot of money into it\" | \"spend a lot of money on it\" | Correct preposition with \"spend money\" is \"on.\" |\n",
      "| Verb forms and agreement | \"I think he need to\" | \"I think he needs to\" | Third-person singular needs \"-s\" (he needs). |\n",
      "| Verb forms and agreement | \"he probably spend a lot of money\" | \"he probably spends a lot of money\" | Third-person singular verb needs \"-s\" in the present simple. |\n",
      "| Verb forms and agreement | \"if he really addicted\" | \"if he’s really addicted\" | \"Addicted\" needs the verb \"be\" (is/’s). |\n",
      "| Pronouns, fillers, repetition | \"increase his social life\" | \"increase their social life\" | Use gender-neutral plural \"their\" when talking about \"people\" in general. |\n",
      "| Pronouns, fillers, repetition | \"activity. activity.\" | \"activity.\" | Word repetition affects fluency; it sounds like hesitation. |\n",
      "| Pronouns, fillers, repetition | \"actually\" (e.g., \"actually they could probably\", \"Actually everyone\") | (Reduce/omit: \"they could probably\" / \"Not everyone can\") | Frequent \"actually\" adds filler and can weaken precision and fluency. |\n",
      "| Pronouns, fillers, repetition | \"I think probably\" | \"probably\" / \"I think\" | Double hedging is repetitive; choose one to sound more direct. |\n",
      "  Context: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: ESL Error Detection (OpenAI via HTTP)\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "OPENAI_MODEL = \"gpt-5.2\"\n",
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "def _extract_transcript_from_replicate(output):\n",
    "    if isinstance(output, dict):\n",
    "        if \"text\" in output and isinstance(output[\"text\"], str):\n",
    "            return output[\"text\"].strip()\n",
    "        segments = output.get(\"segments\")\n",
    "        if isinstance(segments, list):\n",
    "            parts = []\n",
    "            for seg in segments:\n",
    "                if isinstance(seg, dict):\n",
    "                    t = (seg.get(\"text\") or \"\").strip()\n",
    "                    if t:\n",
    "                        parts.append(t)\n",
    "            if parts:\n",
    "                return \" \".join(parts)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Use Whisper transcript if available; otherwise fall back to Replicate output\n",
    "if \"transcript\" not in globals() or not transcript:\n",
    "    transcript = _extract_transcript_from_replicate(\n",
    "        globals().get(\"REPLICATE_DIARIZATION\")\n",
    "    )\n",
    "    if not transcript:\n",
    "        raise RuntimeError(\n",
    "            \"Transcript not available. Run the Whisper/WhisperX cell first.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_issue_type(match):\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"type\", \"UNKNOWN\")\n",
    "    if hasattr(match, \"ruleId\"):\n",
    "        return match.ruleId\n",
    "    if hasattr(match, \"rule_id\"):\n",
    "        return match.rule_id\n",
    "    if hasattr(match, \"rule\"):\n",
    "        rule = match.rule\n",
    "        if isinstance(rule, dict) and \"id\" in rule:\n",
    "            return rule[\"id\"]\n",
    "        if hasattr(rule, \"id\"):\n",
    "            return rule.id\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    print(\"OPENAI_API_KEY not set. Set it to enable OpenAI-based ESL checks.\")\n",
    "    matches = []\n",
    "else:\n",
    "    system_msg = (\n",
    "        '''\n",
    "You are an ESL grammar and fluency analyst focused on IELTS Speaking assessment.\n",
    "\n",
    "Input: a transcript with multiple speakers labeled [SPEAKER_00], [SPEAKER_01], etc.\n",
    "\n",
    "TASK\n",
    "1) Identify the second speaker in order of first appearance.\n",
    "2) Analyze ONLY that speaker’s speech.\n",
    "3) Produce a teacher-facing feedback TABLE that groups common errors and prioritizes them by IELTS impact.\n",
    "\n",
    "NON-NEGOTIABLE RULES\n",
    "- Use ONLY errors that explicitly appear in the transcript.\n",
    "- Quote the student’s exact words for every example.\n",
    "- Do NOT invent, generalize, or paraphrase student language.\n",
    "- Group similar errors together under a clear error category.\n",
    "- Explanations must reflect the REAL grammatical or lexical issue.\n",
    "- Do NOT mention grammar forms that are not used in the correction.\n",
    "- Prioritize errors that most affect IELTS bands (Coherence, Lexical Resource, Grammar).\n",
    "\n",
    "OUTPUT FORMAT (STRICT TABLE)\n",
    "\n",
    "Title: On-the-Fly Feedback Table (Speaker 00)\n",
    "\n",
    "Table columns (exactly these, in this order):\n",
    "1) Error Group (sorted from highest to lowest IELTS impact)\n",
    "2) Student Examples (exact phrases from transcript)\n",
    "3) Better Versions\n",
    "4) Explanation (clear, teacher-ready, 1–2 short lines)\n",
    "\n",
    "SORTING RULE\n",
    "- Order rows by highest IELTS impact first:\n",
    "  1) Coherence / clause structure / logic\n",
    "  2) Collocation and word choice\n",
    "  3) Fixed phrases / prepositions\n",
    "  4) Verb forms and agreement\n",
    "  5) Pronouns, fillers, repetition\n",
    "\n",
    "STYLE CONSTRAINTS\n",
    "- Concise but clear explanations\n",
    "- No paragraphs outside the table\n",
    "- No teaching activities or advice\n",
    "- Teacher-facing language suitable for quick explanation in class\n",
    "        '''\n",
    "    )\n",
    "    user_msg = f\"Transcript:\\n{transcript}\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": OPENAI_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"name\": \"esl_issues\", \"schema\": schema, \"strict\": True},\n",
    "        },\n",
    "    }\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=payload,\n",
    "        timeout=60,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    resp = r.json()\n",
    "\n",
    "    if \"choices\" in resp and len(resp[\"choices\"]) > 0:\n",
    "        content_str = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        data = json.loads(content_str)\n",
    "        matches = data.get(\"issues\", [])\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unexpected response format from OpenAI: {json.dumps(resp, indent=2)}\"\n",
    "        )\n",
    "\n",
    "print(\"ESL ISSUES:\\n\")\n",
    "for m in matches:\n",
    "    if isinstance(m, dict):\n",
    "        print(f\"- {m.get('message', '')}\")\n",
    "        print(f\"  Context: {m.get('context', '')}\")\n",
    "        if m.get(\"suggestion\"):\n",
    "            print(f\"  Suggestion: {m.get('suggestion')}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"- {m.message}\")\n",
    "        print(f\"  Context: {m.context}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd64160-0d69-48e4-a667-0b147feb5347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
