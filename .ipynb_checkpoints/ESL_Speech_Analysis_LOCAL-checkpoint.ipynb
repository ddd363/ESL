{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b603bf",
   "metadata": {},
   "source": [
    "# ESL Speech Analysis (Remote Kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53791366",
   "metadata": {},
   "source": [
    "# Cell 0: Environment Setup (run once)\n",
    "# For .m4a support, pydub needs ffmpeg available in the runtime.\n",
    "!pip install faster-whisper language-tool-python pydub openai replicate -U typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e92c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f7867c075c4c26ac5ccc33a5d8f0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.wav,.m4a', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# FileUpload widget (in-memory)\n",
    "upload = widgets.FileUpload(accept=\".wav,.m4a\", multiple=False)\n",
    "display(upload)\n",
    "\n",
    "# Global variable to hold the audio content\n",
    "AUDIO_BYTES = None\n",
    "AUDIO_FILENAME = None\n",
    "\n",
    "\n",
    "def _iter_uploaded_files(value):\n",
    "    # ipywidgets can return dict-like (v7) or tuple/list (v8)\n",
    "    if hasattr(value, \"items\"):\n",
    "        for name, file_info in value.items():\n",
    "            yield name, file_info\n",
    "    elif isinstance(value, (list, tuple)):\n",
    "        for file_info in value:\n",
    "            name = file_info.get(\"name\") if isinstance(file_info, dict) else None\n",
    "            yield name, file_info\n",
    "\n",
    "\n",
    "def store_audio(change):\n",
    "    global AUDIO_BYTES, AUDIO_FILENAME\n",
    "    if not upload.value:\n",
    "        return\n",
    "    for name, file_info in _iter_uploaded_files(upload.value):\n",
    "        if isinstance(file_info, dict):\n",
    "            AUDIO_BYTES = file_info.get(\"content\")\n",
    "            AUDIO_FILENAME = name or file_info.get(\"name\")\n",
    "            if AUDIO_BYTES and AUDIO_FILENAME:\n",
    "                print(\n",
    "                    f\"Audio file '{AUDIO_FILENAME}' is now ready in memory for other cells.\"\n",
    "                )\n",
    "\n",
    "\n",
    "# Automatically trigger when a file is uploaded\n",
    "upload.observe(store_audio, names=\"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9664cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file loaded from upload: audio/hobbies alternative girl.wav\n"
     ]
    },
    {
     "ename": "ReplicateError",
     "evalue": "ReplicateError Details:\nstatus: 401\ndetail: Invalid token",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReplicateError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m NUM_SPEAKERS:\n\u001b[32m     92\u001b[39m         input_payload[\u001b[33m\"\u001b[39m\u001b[33mnum_speakers\u001b[39m\u001b[33m\"\u001b[39m] = NUM_SPEAKERS\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     replicate_output = \u001b[43mreplicate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43minput_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Save results for downstream use\u001b[39;00m\n\u001b[32m     99\u001b[39m REPLICATE_DIARIZATION = replicate_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/client.py:175\u001b[39m, in \u001b[36mClient.run\u001b[39m\u001b[34m(self, ref, input, use_file_output, **params)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    165\u001b[39m     ref: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     **params: Unpack[\u001b[33m\"\u001b[39m\u001b[33mPredictions.CreatePredictionParams\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    170\u001b[39m ) -> Union[Any, Iterator[Any]]:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[33;03m    Run a model and wait for its output.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_file_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_file_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/run.py:46\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(client, ref, input, use_file_output, **params)\u001b[39m\n\u001b[32m     43\u001b[39m version, owner, name, version_id = identifier._resolve(ref)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     prediction = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m owner \u001b[38;5;129;01mand\u001b[39;00m name:\n\u001b[32m     50\u001b[39m     prediction = client.models.predictions.create(\n\u001b[32m     51\u001b[39m         model=(owner, name), \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m {}, **params\n\u001b[32m     52\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/prediction.py:485\u001b[39m, in \u001b[36mPredictions.create\u001b[39m\u001b[34m(self, model, version, deployment, input, *args, **params)\u001b[39m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Deployments(\u001b[38;5;28mself\u001b[39m._client).predictions.create(\n\u001b[32m    479\u001b[39m         deployment=deployment,\n\u001b[32m    480\u001b[39m         \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m    481\u001b[39m         **params,\n\u001b[32m    482\u001b[39m     )\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mencode_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile_encoding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_encoding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m body = _create_prediction_body(\n\u001b[32m    492\u001b[39m     version,\n\u001b[32m    493\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    494\u001b[39m     **params,\n\u001b[32m    495\u001b[39m )\n\u001b[32m    496\u001b[39m extras = _create_prediction_request_params(wait=wait)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/helpers.py:36\u001b[39m, in \u001b[36mencode_json\u001b[39m\u001b[34m(obj, client, file_encoding_strategy)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mReturn a JSON-compatible version of the object.\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         key: \u001b[43mencode_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_encoding_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m obj.items()\n\u001b[32m     38\u001b[39m     }\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m, GeneratorType, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [encode_json(value, client, file_encoding_strategy) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/helpers.py:47\u001b[39m, in \u001b[36mencode_json\u001b[39m\u001b[34m(obj, client, file_encoding_strategy)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file_encoding_strategy == \u001b[33m\"\u001b[39m\u001b[33mbase64\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m base64_encode_file(obj)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m.urls[\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m HAS_NUMPY:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np.integer):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/file.py:83\u001b[39m, in \u001b[36mFiles.create\u001b[39m\u001b[34m(self, file, **params)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, (io.IOBase, BinaryIO)):\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     80\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnsupported file type. Must be a file path or file-like object.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_create_file_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _json_to_file(resp.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/client.py:89\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, method, path, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, **kwargs) -> httpx.Response:\n\u001b[32m     88\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._client.request(method, path, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/project1/lib/python3.12/site-packages/replicate/client.py:407\u001b[39m, in \u001b[36m_raise_for_status\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_for_status\u001b[39m(resp: httpx.Response) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= resp.status_code < \u001b[32m600\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ReplicateError.from_response(resp)\n",
      "\u001b[31mReplicateError\u001b[39m: ReplicateError Details:\nstatus: 401\ndetail: Invalid token"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load most recent audio file from ./audio (.wav or .m4a)\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "AUDIO_DIR = \"audio\"\n",
    "SUPPORTED_EXTS = {\".wav\", \".m4a\"}\n",
    "\n",
    "# Prefer in-memory upload if present\n",
    "if \"AUDIO_BYTES\" in globals() and AUDIO_BYTES and AUDIO_FILENAME:\n",
    "    ext = os.path.splitext(AUDIO_FILENAME)[1].lower()\n",
    "    if ext not in SUPPORTED_EXTS:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.join(\n",
    "            AUDIO_DIR, os.path.splitext(AUDIO_FILENAME)[0] + \".wav\"\n",
    "        )\n",
    "        audio = AudioSegment.from_file(io.BytesIO(AUDIO_BYTES), format=\"m4a\")\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    else:\n",
    "        AUDIO_PATH = os.path.join(AUDIO_DIR, AUDIO_FILENAME)\n",
    "        with open(AUDIO_PATH, \"wb\") as f:\n",
    "            f.write(AUDIO_BYTES)\n",
    "\n",
    "    print(f\"Audio file loaded from upload: {AUDIO_PATH}\")\n",
    "else:\n",
    "    if not os.path.isdir(AUDIO_DIR):\n",
    "        raise FileNotFoundError(f\"Directory not found: {AUDIO_DIR}\")\n",
    "\n",
    "    candidates = [\n",
    "        os.path.join(AUDIO_DIR, f)\n",
    "        for f in os.listdir(AUDIO_DIR)\n",
    "        if os.path.splitext(f)[1].lower() in SUPPORTED_EXTS\n",
    "        and os.path.isfile(os.path.join(AUDIO_DIR, f))\n",
    "    ]\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            \"No .wav or .m4a files found in ./audio. Add a file and try again.\"\n",
    "        )\n",
    "\n",
    "    INPUT_PATH = max(candidates, key=os.path.getmtime)\n",
    "\n",
    "    ext = os.path.splitext(INPUT_PATH)[1].lower()\n",
    "\n",
    "    if ext == \".m4a\":\n",
    "        AUDIO_PATH = os.path.splitext(INPUT_PATH)[0] + \".wav\"\n",
    "        audio = AudioSegment.from_file(INPUT_PATH, format=\"m4a\")\n",
    "        # Convert to mono/16k for best Whisper results\n",
    "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "        audio.export(AUDIO_PATH, format=\"wav\")\n",
    "    elif ext == \".wav\":\n",
    "        AUDIO_PATH = INPUT_PATH\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use .wav or .m4a.\")\n",
    "\n",
    "    print(f\"Audio file loaded: {AUDIO_PATH}\")\n",
    "\n",
    "\n",
    "# Cell 0c: Replicate diarization (Whisper + diarization as a service)\n",
    "# Put your Replicate API key here (or set in environment before running):\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_UdBzdYuIUsDW5MWGvuvgchX7FrxJvho3Vj88j\"\n",
    "\n",
    "import os\n",
    "import replicate\n",
    "\n",
    "# Ensure audio is prepared (run Cell 1 first to set AUDIO_PATH)\n",
    "if \"AUDIO_PATH\" not in globals():\n",
    "    raise RuntimeError(\"AUDIO_PATH not set. Run the audio load cell first.\")\n",
    "\n",
    "if not os.environ.get(\"REPLICATE_API_TOKEN\"):\n",
    "    raise RuntimeError(\"REPLICATE_API_TOKEN not set. Add it in this cell and re-run.\")\n",
    "\n",
    "# Replicate diarization settings\n",
    "NUM_SPEAKERS = 2  # set to None to autodetect\n",
    "GROUP_SEGMENTS = True  # merge short same-speaker segments\n",
    "\n",
    "# Run diarization on Replicate (pin to a model version)\n",
    "\n",
    "model_id = \"thomasmol/whisper-diarization:1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886\"\n",
    "with open(AUDIO_PATH, \"rb\") as f:\n",
    "    input_payload = {\n",
    "        \"file\": f,\n",
    "        \"output\": \"json\",\n",
    "        \"group_segments\": GROUP_SEGMENTS,\n",
    "    }\n",
    "    if NUM_SPEAKERS:\n",
    "        input_payload[\"num_speakers\"] = NUM_SPEAKERS\n",
    "    replicate_output = replicate.run(\n",
    "        model_id,\n",
    "        input=input_payload,\n",
    "    )\n",
    "\n",
    "# Save results for downstream use\n",
    "REPLICATE_DIARIZATION = replicate_output\n",
    "\n",
    "# print(\"Replicate diarization output:\")\n",
    "# print(replicate_output)\n",
    "\n",
    "\n",
    "# Cell 2: Human-readable diarization output (from Replicate)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def _format_time(sec):\n",
    "    m = int(sec // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{m:02d}:{s:05.2f}\"\n",
    "\n",
    "\n",
    "def _normalize_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = re.sub(r\"[\\W_]+\", \"\", t)\n",
    "    return t\n",
    "\n",
    "\n",
    "def _dedupe_sentences(text):\n",
    "    # Remove consecutive duplicate sentences after splitting on punctuation\n",
    "    parts = re.split(r\"(?<=[.!?])\\s+\", text.strip())\n",
    "    out = []\n",
    "    last_norm = None\n",
    "    for p in parts:\n",
    "        if not p:\n",
    "            continue\n",
    "        norm = _normalize_text(p)\n",
    "        if norm and norm == last_norm:\n",
    "            continue\n",
    "        out.append(p)\n",
    "        last_norm = norm\n",
    "    return \" \".join(out)\n",
    "\n",
    "\n",
    "def _merge_segments(segments):\n",
    "    merged = []\n",
    "    last_text_norm = None\n",
    "    for seg in segments:\n",
    "        speaker = seg.get(\"speaker\") or \"UNKNOWN\"\n",
    "        text = (seg.get(\"text\") or \"\").strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        start = seg.get(\"start\", 0.0)\n",
    "        end = seg.get(\"end\", 0.0)\n",
    "        # If speaker is UNKNOWN, stick with previous speaker when possible\n",
    "        if speaker == \"UNKNOWN\" and merged:\n",
    "            speaker = merged[-1][\"speaker\"]\n",
    "        text = _dedupe_sentences(text)\n",
    "        text_norm = _normalize_text(text)\n",
    "        if text_norm and text_norm == last_text_norm:\n",
    "            # Skip exact repeat chunk\n",
    "            continue\n",
    "        if merged and merged[-1][\"speaker\"] == speaker:\n",
    "            # Merge consecutive same-speaker chunks\n",
    "            merged[-1][\"end\"] = end\n",
    "            merged[-1][\"text\"] += \" \" + text\n",
    "        else:\n",
    "            merged.append(\n",
    "                {\"speaker\": speaker, \"start\": start, \"end\": end, \"text\": text}\n",
    "            )\n",
    "        last_text_norm = text_norm\n",
    "    return merged\n",
    "\n",
    "\n",
    "def _pretty_print_replicate(output):\n",
    "    if not output:\n",
    "        print(\n",
    "            \"No Replicate output available. Run the Replicate diarization cell first.\"\n",
    "        )\n",
    "        return\n",
    "    # Replicate returns a dict with `segments` or a list in some cases\n",
    "    segments = None\n",
    "    if isinstance(output, dict):\n",
    "        segments = output.get(\"segments\")\n",
    "    elif isinstance(output, list):\n",
    "        segments = output\n",
    "    if not segments:\n",
    "        print(\"No segments found in Replicate output.\")\n",
    "        return\n",
    "    merged = _merge_segments(segments)\n",
    "    if not merged:\n",
    "        print(\"No usable segments after merging.\")\n",
    "        return\n",
    "    print(\"HUMAN-READABLE DIARIZATION:\\n\")\n",
    "    last_speaker = None\n",
    "    for seg in merged:\n",
    "        speaker = seg[\"speaker\"]\n",
    "        start = _format_time(seg.get(\"start\", 0.0))\n",
    "        end = _format_time(seg.get(\"end\", 0.0))\n",
    "        text = seg[\"text\"]\n",
    "        if speaker != last_speaker:\n",
    "            print(f\"[{speaker}] {start}–{end}: {text}\")\n",
    "            last_speaker = speaker\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "\n",
    "# Use saved output from the Replicate cell\n",
    "_pretty_print_replicate(globals().get(\"REPLICATE_DIARIZATION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db067a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESL ISSUES:\n",
      "\n",
      "- On-the-Fly Feedback Table (Speaker 00)\n",
      "\n",
      "| Error Group (sorted from highest to lowest IELTS impact) | Student Examples (exact phrases from transcript) | Better Versions | Explanation (clear, teacher-ready, 1–2 short lines) |\n",
      "|---|---|---|---|\n",
      "| Coherence / clause structure / logic | \"I think sometimes people need some casual social life that if they have a hobby actually they could probably\" | \"I think people sometimes want a casual social life, and having a hobby can help.\" | The sentence structure is tangled (\"that if...\") and weakens clarity and coherence. |\n",
      "| Coherence / clause structure / logic | \"Actually everyone could do it because as we know it's very expensive\" | \"Actually, not everyone can do it because, as we know, it’s very expensive.\" | Logical connector is wrong (\"everyone could\" conflicts with \"very expensive\"). |\n",
      "| Coherence / clause structure / logic | \"if he really addicted to a sports car\" | \"if he’s really addicted to sports cars\" | Missing verb \"is/’s\" and unclear noun use reduce clarity. |\n",
      "| Coherence / clause structure / logic | \"forget what happened for the day walk\" | \"forget what happened during the day\" | The ending phrase is not logical/clear, so meaning is hard to follow. |\n",
      "| Collocation and word choice | \"connect stamp\" | \"collect stamps\" | Wrong verb for the activity; \"collect\" is the natural collocation. |\n",
      "| Collocation and word choice | \"connect a sports car\" | \"collect sports cars\" | Wrong verb choice; \"connect\" doesn’t match this meaning. |\n",
      "| Collocation and word choice | \"share the feeling\" | \"share their feelings\" / \"share the experience\" | \"share the feeling\" is unnatural here; use plural \"feelings\" or \"experience.\" |\n",
      "| Fixed phrases / prepositions | \"what kind of hobbies to have\" | \"what kind of hobbies they have\" | In a statement, use subject + verb order, not an infinitive structure. |\n",
      "| Fixed phrases / prepositions | \"spend a lot of money into it\" | \"spend a lot of money on it\" | Correct preposition with \"spend money\" is \"on.\" |\n",
      "| Verb forms and agreement | \"I think he need to\" | \"I think he needs to\" | Third-person singular needs \"-s\" (he needs). |\n",
      "| Verb forms and agreement | \"he probably spend a lot of money\" | \"he probably spends a lot of money\" | Third-person singular verb needs \"-s\" in the present simple. |\n",
      "| Verb forms and agreement | \"if he really addicted\" | \"if he’s really addicted\" | \"Addicted\" needs the verb \"be\" (is/’s). |\n",
      "| Pronouns, fillers, repetition | \"increase his social life\" | \"increase their social life\" | Use gender-neutral plural \"their\" when talking about \"people\" in general. |\n",
      "| Pronouns, fillers, repetition | \"activity. activity.\" | \"activity.\" | Word repetition affects fluency; it sounds like hesitation. |\n",
      "| Pronouns, fillers, repetition | \"actually\" (e.g., \"actually they could probably\", \"Actually everyone\") | (Reduce/omit: \"they could probably\" / \"Not everyone can\") | Frequent \"actually\" adds filler and can weaken precision and fluency. |\n",
      "| Pronouns, fillers, repetition | \"I think probably\" | \"probably\" / \"I think\" | Double hedging is repetitive; choose one to sound more direct. |\n",
      "  Context: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: ESL Error Detection (OpenAI via HTTP)\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "OPENAI_MODEL = \"gpt-5.2\"\n",
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "def _extract_transcript_from_replicate(output):\n",
    "    if isinstance(output, dict):\n",
    "        if \"text\" in output and isinstance(output[\"text\"], str):\n",
    "            return output[\"text\"].strip()\n",
    "        segments = output.get(\"segments\")\n",
    "        if isinstance(segments, list):\n",
    "            parts = []\n",
    "            for seg in segments:\n",
    "                if isinstance(seg, dict):\n",
    "                    t = (seg.get(\"text\") or \"\").strip()\n",
    "                    if t:\n",
    "                        parts.append(t)\n",
    "            if parts:\n",
    "                return \" \".join(parts)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Use Whisper transcript if available; otherwise fall back to Replicate output\n",
    "if \"transcript\" not in globals() or not transcript:\n",
    "    transcript = _extract_transcript_from_replicate(\n",
    "        globals().get(\"REPLICATE_DIARIZATION\")\n",
    "    )\n",
    "    if not transcript:\n",
    "        raise RuntimeError(\n",
    "            \"Transcript not available. Run the Whisper/WhisperX cell first.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_issue_type(match):\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"type\", \"UNKNOWN\")\n",
    "    if hasattr(match, \"ruleId\"):\n",
    "        return match.ruleId\n",
    "    if hasattr(match, \"rule_id\"):\n",
    "        return match.rule_id\n",
    "    if hasattr(match, \"rule\"):\n",
    "        rule = match.rule\n",
    "        if isinstance(rule, dict) and \"id\" in rule:\n",
    "            return rule[\"id\"]\n",
    "        if hasattr(rule, \"id\"):\n",
    "            return rule.id\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "if not api_key:\n",
    "    print(\"OPENAI_API_KEY not set. Set it to enable OpenAI-based ESL checks.\")\n",
    "    matches = []\n",
    "else:\n",
    "    system_msg = (\n",
    "        '''\n",
    "You are an ESL grammar and fluency analyst focused on IELTS Speaking assessment.\n",
    "\n",
    "Input: a transcript with multiple speakers labeled [SPEAKER_00], [SPEAKER_01], etc.\n",
    "\n",
    "TASK\n",
    "1) Identify the second speaker in order of first appearance.\n",
    "2) Analyze ONLY that speaker’s speech.\n",
    "3) Produce a teacher-facing feedback TABLE that groups common errors and prioritizes them by IELTS impact.\n",
    "\n",
    "NON-NEGOTIABLE RULES\n",
    "- Use ONLY errors that explicitly appear in the transcript.\n",
    "- Quote the student’s exact words for every example.\n",
    "- Do NOT invent, generalize, or paraphrase student language.\n",
    "- Group similar errors together under a clear error category.\n",
    "- Explanations must reflect the REAL grammatical or lexical issue.\n",
    "- Do NOT mention grammar forms that are not used in the correction.\n",
    "- Prioritize errors that most affect IELTS bands (Coherence, Lexical Resource, Grammar).\n",
    "\n",
    "OUTPUT FORMAT (STRICT TABLE)\n",
    "\n",
    "Title: On-the-Fly Feedback Table (Speaker 00)\n",
    "\n",
    "Table columns (exactly these, in this order):\n",
    "1) Error Group (sorted from highest to lowest IELTS impact)\n",
    "2) Student Examples (exact phrases from transcript)\n",
    "3) Better Versions\n",
    "4) Explanation (clear, teacher-ready, 1–2 short lines)\n",
    "\n",
    "SORTING RULE\n",
    "- Order rows by highest IELTS impact first:\n",
    "  1) Coherence / clause structure / logic\n",
    "  2) Collocation and word choice\n",
    "  3) Fixed phrases / prepositions\n",
    "  4) Verb forms and agreement\n",
    "  5) Pronouns, fillers, repetition\n",
    "\n",
    "STYLE CONSTRAINTS\n",
    "- Concise but clear explanations\n",
    "- No paragraphs outside the table\n",
    "- No teaching activities or advice\n",
    "- Teacher-facing language suitable for quick explanation in class\n",
    "        '''\n",
    "    )\n",
    "    user_msg = f\"Transcript:\\n{transcript}\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": OPENAI_MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        \"response_format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\"name\": \"esl_issues\", \"schema\": schema, \"strict\": True},\n",
    "        },\n",
    "    }\n",
    "    r = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json=payload,\n",
    "        timeout=60,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    resp = r.json()\n",
    "\n",
    "    if \"choices\" in resp and len(resp[\"choices\"]) > 0:\n",
    "        content_str = resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        data = json.loads(content_str)\n",
    "        matches = data.get(\"issues\", [])\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unexpected response format from OpenAI: {json.dumps(resp, indent=2)}\"\n",
    "        )\n",
    "\n",
    "print(\"ESL ISSUES:\\n\")\n",
    "for m in matches:\n",
    "    if isinstance(m, dict):\n",
    "        print(f\"- {m.get('message', '')}\")\n",
    "        print(f\"  Context: {m.get('context', '')}\")\n",
    "        if m.get(\"suggestion\"):\n",
    "            print(f\"  Suggestion: {m.get('suggestion')}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"- {m.message}\")\n",
    "        print(f\"  Context: {m.context}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd64160-0d69-48e4-a667-0b147feb5347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
